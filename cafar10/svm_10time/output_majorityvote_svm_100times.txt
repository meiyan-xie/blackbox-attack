Starting /home/m/mx42/.bash_profile ... standard AFS bash profile

========================
Home directory : /home/m/mx42 is not in AFS -- skipping quota check
========================

On host node413 :
	 13:18:21 up 37 days,  2:36,  0 users,  load average: 0.00, 0.00, 0.00

=== === === Your Kerberos ticket and AFS token status === === ===
Kerberos : 
AFS      : 

=== === === Start Python Information === === ===
1. The default python is Anaconda Python 3

2. To instead use Anaconda Python 2 :

	echo 'module load python2' > ~/.modules

	Then log out / log in 
=== === === End Python Information === === ===

Running your ~/.modules file:

Running your /home/m/mx42/.modules file:
Saving test_data after shuffling
Saving test_label after shuffling
Oracle model evaluation on clean data #9800:
External call
Accuracy = 10.2755% (1007/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 9.97959% (978/9800)
Accuracy = 10.1429% (994/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 10.2551% (1005/9800)
Accuracy = 9.94898% (975/9800)
Accuracy = 10.1224% (992/9800)
Accuracy = 9.85714% (966/9800)
Accuracy = 10% (980/9800)
Accuracy = 10.1327% (993/9800)
Accuracy = 9.97959% (978/9800)
Accuracy = 9.94898% (975/9800)
Accuracy = 10.2959% (1009/9800)
Accuracy = 10.2449% (1004/9800)
Accuracy = 9.5% (931/9800)
Accuracy = 10.2041% (1000/9800)
Accuracy = 10.1327% (993/9800)
Accuracy = 9.63265% (944/9800)
Accuracy = 9.92857% (973/9800)
Accuracy = 9.93878% (974/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 10.1735% (997/9800)
Accuracy = 10.5204% (1031/9800)
Accuracy = 9.89796% (970/9800)
Accuracy = 10.102% (990/9800)
Accuracy = 10.0102% (981/9800)
Accuracy = 10.0408% (984/9800)
Accuracy = 9.89796% (970/9800)
Accuracy = 9.94898% (975/9800)
Accuracy = 9.81633% (962/9800)
Accuracy = 10.2347% (1003/9800)
Accuracy = 10.2857% (1008/9800)
Accuracy = 10.1837% (998/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 9.65306% (946/9800)
Accuracy = 9.72449% (953/9800)
Accuracy = 10.1735% (997/9800)
Accuracy = 9.91837% (972/9800)
Accuracy = 10.2143% (1001/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 10.1429% (994/9800)
Accuracy = 10.1429% (994/9800)
Accuracy = 10.3571% (1015/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 10.2347% (1003/9800)
Accuracy = 9.93878% (974/9800)
Accuracy = 9.68367% (949/9800)
Accuracy = 9.94898% (975/9800)
Accuracy = 9.65306% (946/9800)
Accuracy = 9.69388% (950/9800)
Accuracy = 10.1429% (994/9800)
Accuracy = 10.2347% (1003/9800)
Accuracy = 10.2653% (1006/9800)
Accuracy = 10.4184% (1021/9800)
Accuracy = 10.102% (990/9800)
Accuracy = 9.88776% (969/9800)
Accuracy = 10.2551% (1005/9800)
Accuracy = 9.54082% (935/9800)
Accuracy = 9.92857% (973/9800)
Accuracy = 10.2959% (1009/9800)
Accuracy = 10.1837% (998/9800)
Accuracy = 10.1429% (994/9800)
Accuracy = 10.051% (985/9800)
Accuracy = 9.89796% (970/9800)
Accuracy = 9.95918% (976/9800)
Accuracy = 10.0306% (983/9800)
Accuracy = 9.93878% (974/9800)
Accuracy = 10.3469% (1014/9800)
Accuracy = 10.0918% (989/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 9.64286% (945/9800)
Accuracy = 10.0204% (982/9800)
Accuracy = 10.0204% (982/9800)
Accuracy = 10.0306% (983/9800)
Accuracy = 10.0408% (984/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 10.2449% (1004/9800)
Accuracy = 10.1429% (994/9800)
Accuracy = 9.78571% (959/9800)
Accuracy = 10.0204% (982/9800)
Accuracy = 10.2041% (1000/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 10.051% (985/9800)
Accuracy = 9.82653% (963/9800)
Accuracy = 10.0102% (981/9800)
Accuracy = 10.3469% (1014/9800)
Accuracy = 10.0816% (988/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 10.1327% (993/9800)
Accuracy = 10.3061% (1010/9800)
Accuracy = 9.85714% (966/9800)
Accuracy = 10.2653% (1006/9800)
Accuracy = 10.3061% (1010/9800)
Accuracy = 10.3776% (1017/9800)
Accuracy = 10.0918% (989/9800)
Accuracy = 10.1735% (997/9800)
Load prediction file and append to a list
correct_count:  3794
Test accuray tensor:  0.3871428571428571
Initialized weights
Epoch #0:
Current x_sub's size is 200
External call
Accuracy = 12.5% (25/200)
Accuracy = 10.5% (21/200)
Accuracy = 11% (22/200)
Accuracy = 9% (18/200)
Accuracy = 12.5% (25/200)
Accuracy = 11.5% (23/200)
Accuracy = 11% (22/200)
Accuracy = 9% (18/200)
Accuracy = 7.5% (15/200)
Accuracy = 11% (22/200)
Accuracy = 11% (22/200)
Accuracy = 9.5% (19/200)
Accuracy = 11% (22/200)
Accuracy = 10% (20/200)
Accuracy = 9% (18/200)
Accuracy = 12.5% (25/200)
Accuracy = 9.5% (19/200)
Accuracy = 12% (24/200)
Accuracy = 11% (22/200)
Accuracy = 12% (24/200)
Accuracy = 8.5% (17/200)
Accuracy = 12.5% (25/200)
Accuracy = 9.5% (19/200)
Accuracy = 10% (20/200)
Accuracy = 8% (16/200)
Accuracy = 9% (18/200)
Accuracy = 12.5% (25/200)
Accuracy = 9.5% (19/200)
Accuracy = 9% (18/200)
Accuracy = 12% (24/200)
Accuracy = 15.5% (31/200)
Accuracy = 9.5% (19/200)
Accuracy = 12% (24/200)
Accuracy = 10% (20/200)
Accuracy = 10.5% (21/200)
Accuracy = 13% (26/200)
Accuracy = 13.5% (27/200)
Accuracy = 11.5% (23/200)
Accuracy = 10.5% (21/200)
Accuracy = 9.5% (19/200)
Accuracy = 11.5% (23/200)
Accuracy = 8.5% (17/200)
Accuracy = 9% (18/200)
Accuracy = 11% (22/200)
Accuracy = 12% (24/200)
Accuracy = 13.5% (27/200)
Accuracy = 12.5% (25/200)
Accuracy = 12% (24/200)
Accuracy = 9% (18/200)
Accuracy = 10.5% (21/200)
Accuracy = 10.5% (21/200)
Accuracy = 11.5% (23/200)
Accuracy = 10% (20/200)
Accuracy = 11.5% (23/200)
Accuracy = 11% (22/200)
Accuracy = 10% (20/200)
Accuracy = 9% (18/200)
Accuracy = 14% (28/200)
Accuracy = 9.5% (19/200)
Accuracy = 10.5% (21/200)
Accuracy = 9% (18/200)
Accuracy = 10% (20/200)
Accuracy = 10% (20/200)
Accuracy = 12% (24/200)
Accuracy = 8% (16/200)
Accuracy = 9% (18/200)
Accuracy = 10% (20/200)
Accuracy = 9% (18/200)
Accuracy = 12% (24/200)
Accuracy = 13.5% (27/200)
Accuracy = 11.5% (23/200)
Accuracy = 10.5% (21/200)
Accuracy = 13% (26/200)
Accuracy = 11.5% (23/200)
Accuracy = 10.5% (21/200)
Accuracy = 11% (22/200)
Accuracy = 14% (28/200)
Accuracy = 10% (20/200)
Accuracy = 9% (18/200)
Accuracy = 10.5% (21/200)
Accuracy = 11.5% (23/200)
Accuracy = 10% (20/200)
Accuracy = 9% (18/200)
Accuracy = 10.5% (21/200)
Accuracy = 11.5% (23/200)
Accuracy = 8.5% (17/200)
Accuracy = 12.5% (25/200)
Accuracy = 10% (20/200)
Accuracy = 8.5% (17/200)
Accuracy = 13.5% (27/200)
Accuracy = 12.5% (25/200)
Accuracy = 7.5% (15/200)
Accuracy = 9.5% (19/200)
Accuracy = 8.5% (17/200)
Accuracy = 7.5% (15/200)
Accuracy = 11.5% (23/200)
Accuracy = 9.5% (19/200)
Accuracy = 8% (16/200)
Accuracy = 8.5% (17/200)
Accuracy = 10% (20/200)
Load prediction file and append to a list
Get label for x_sub cost 16.0
Substitute data augmentation processing
Augmentation cost 0.7 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Oracle model FGSM attack's accuracy on adversarial samples #9800:
External call
Accuracy = 10.3367% (1013/9800)
Accuracy = 10.051% (985/9800)
Accuracy = 10.4694% (1026/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 10.2347% (1003/9800)
Accuracy = 10.3673% (1016/9800)
Accuracy = 10.4286% (1022/9800)
Accuracy = 10.5612% (1035/9800)
Accuracy = 10.4082% (1020/9800)
Accuracy = 10.1837% (998/9800)
Accuracy = 10.6531% (1044/9800)
Accuracy = 10% (980/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 10.5102% (1030/9800)
Accuracy = 10.1531% (995/9800)
Accuracy = 10.4286% (1022/9800)
Accuracy = 10.7449% (1053/9800)
Accuracy = 10.4286% (1022/9800)
Accuracy = 10.5918% (1038/9800)
Accuracy = 10.5204% (1031/9800)
Accuracy = 10.5% (1029/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 10.4592% (1025/9800)
Accuracy = 10.6224% (1041/9800)
Accuracy = 9.92857% (973/9800)
Accuracy = 10.0714% (987/9800)
Accuracy = 10.4592% (1025/9800)
Accuracy = 10.3878% (1018/9800)
Accuracy = 10.5612% (1035/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 10.1837% (998/9800)
Accuracy = 10.5102% (1030/9800)
Accuracy = 10.2449% (1004/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 10.1429% (994/9800)
Accuracy = 10.2143% (1001/9800)
Accuracy = 9.32653% (914/9800)
Accuracy = 9.90816% (971/9800)
Accuracy = 10.4796% (1027/9800)
Accuracy = 10.4082% (1020/9800)
Accuracy = 10.4184% (1021/9800)
Accuracy = 9.70408% (951/9800)
Accuracy = 10.551% (1034/9800)
Accuracy = 10.398% (1019/9800)
Accuracy = 10.3776% (1017/9800)
Accuracy = 10.2245% (1002/9800)
Accuracy = 10.551% (1034/9800)
Accuracy = 10.3265% (1012/9800)
Accuracy = 10.2041% (1000/9800)
Accuracy = 10.4694% (1026/9800)
Accuracy = 10.0204% (982/9800)
Accuracy = 9.83673% (964/9800)
Accuracy = 10.6122% (1040/9800)
Accuracy = 10.2551% (1005/9800)
Accuracy = 10.3367% (1013/9800)
Accuracy = 10.2653% (1006/9800)
Accuracy = 10.3265% (1012/9800)
Accuracy = 9.77551% (958/9800)
Accuracy = 10.4082% (1020/9800)
Accuracy = 10.5102% (1030/9800)
Accuracy = 10.2449% (1004/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 10.398% (1019/9800)
Accuracy = 10.6327% (1042/9800)
Accuracy = 10.3367% (1013/9800)
Accuracy = 10.1531% (995/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 9.89796% (970/9800)
Accuracy = 10.7653% (1055/9800)
Accuracy = 10.551% (1034/9800)
Accuracy = 10.8061% (1059/9800)
Accuracy = 10.1531% (995/9800)
Accuracy = 10.3163% (1011/9800)
Accuracy = 10.3776% (1017/9800)
Accuracy = 10.4184% (1021/9800)
Accuracy = 9.87755% (968/9800)
Accuracy = 10.5% (1029/9800)
Accuracy = 10.398% (1019/9800)
Accuracy = 10.3673% (1016/9800)
Accuracy = 10.3163% (1011/9800)
Accuracy = 10.602% (1039/9800)
Accuracy = 10.602% (1039/9800)
Accuracy = 10.1735% (997/9800)
Accuracy = 10.3265% (1012/9800)
Accuracy = 9.95918% (976/9800)
Accuracy = 10.9388% (1072/9800)
Accuracy = 10.8776% (1066/9800)
Accuracy = 10.4898% (1028/9800)
Accuracy = 10.0102% (981/9800)
Accuracy = 10.1224% (992/9800)
Accuracy = 10.2551% (1005/9800)
Accuracy = 10.3163% (1011/9800)
Accuracy = 10.7857% (1057/9800)
Accuracy = 10.2347% (1003/9800)
Accuracy = 10% (980/9800)
Accuracy = 10.5612% (1035/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 10.2959% (1009/9800)
Accuracy = 10.2041% (1000/9800)
Accuracy = 10.2755% (1007/9800)
Load prediction file and append to a list
correct_count:  2107
Test accuray tensor:  0.215
Epoch #1:
Current x_sub's size is 400
External call
Accuracy = 11.25% (45/400)
Accuracy = 7.5% (30/400)
Accuracy = 8.5% (34/400)
Accuracy = 6.75% (27/400)
Accuracy = 10.75% (43/400)
Accuracy = 8% (32/400)
Accuracy = 8.75% (35/400)
Accuracy = 11.5% (46/400)
Accuracy = 10% (40/400)
Accuracy = 11% (44/400)
Accuracy = 9.5% (38/400)
Accuracy = 11.25% (45/400)
Accuracy = 8% (32/400)
Accuracy = 9.5% (38/400)
Accuracy = 8.75% (35/400)
Accuracy = 9% (36/400)
Accuracy = 11% (44/400)
Accuracy = 10.25% (41/400)
Accuracy = 9.75% (39/400)
Accuracy = 10.75% (43/400)
Accuracy = 9.5% (38/400)
Accuracy = 9.5% (38/400)
Accuracy = 12.25% (49/400)
Accuracy = 10% (40/400)
Accuracy = 8.5% (34/400)
Accuracy = 10.25% (41/400)
Accuracy = 8.5% (34/400)
Accuracy = 9.25% (37/400)
Accuracy = 10.5% (42/400)
Accuracy = 8.75% (35/400)
Accuracy = 7.5% (30/400)
Accuracy = 10% (40/400)
Accuracy = 8% (32/400)
Accuracy = 12% (48/400)
Accuracy = 10.75% (43/400)
Accuracy = 9.5% (38/400)
Accuracy = 9.75% (39/400)
Accuracy = 8.75% (35/400)
Accuracy = 11.75% (47/400)
Accuracy = 9.25% (37/400)
Accuracy = 8.25% (33/400)
Accuracy = 9.5% (38/400)
Accuracy = 9.75% (39/400)
Accuracy = 9.5% (38/400)
Accuracy = 8.75% (35/400)
Accuracy = 10% (40/400)
Accuracy = 9.75% (39/400)
Accuracy = 9.25% (37/400)
Accuracy = 7.5% (30/400)
Accuracy = 11.5% (46/400)
Accuracy = 12.25% (49/400)
Accuracy = 8% (32/400)
Accuracy = 8.25% (33/400)
Accuracy = 11.25% (45/400)
Accuracy = 9.75% (39/400)
Accuracy = 9.25% (37/400)
Accuracy = 11.25% (45/400)
Accuracy = 11.5% (46/400)
Accuracy = 9.5% (38/400)
Accuracy = 9% (36/400)
Accuracy = 11.75% (47/400)
Accuracy = 9.5% (38/400)
Accuracy = 10.25% (41/400)
Accuracy = 12% (48/400)
Accuracy = 9% (36/400)
Accuracy = 7.75% (31/400)
Accuracy = 10% (40/400)
Accuracy = 7.5% (30/400)
Accuracy = 8% (32/400)
Accuracy = 9.25% (37/400)
Accuracy = 8.5% (34/400)
Accuracy = 8% (32/400)
Accuracy = 8.25% (33/400)
Accuracy = 10% (40/400)
Accuracy = 10.25% (41/400)
Accuracy = 9.75% (39/400)
Accuracy = 9.75% (39/400)
Accuracy = 9.75% (39/400)
Accuracy = 9.25% (37/400)
Accuracy = 9.25% (37/400)
Accuracy = 9.5% (38/400)
Accuracy = 10.25% (41/400)
Accuracy = 9.25% (37/400)
Accuracy = 11% (44/400)
Accuracy = 8.5% (34/400)
Accuracy = 11.25% (45/400)
Accuracy = 9.75% (39/400)
Accuracy = 13% (52/400)
Accuracy = 9.75% (39/400)
Accuracy = 11.75% (47/400)
Accuracy = 10.25% (41/400)
Accuracy = 11% (44/400)
Accuracy = 10.25% (41/400)
Accuracy = 9% (36/400)
Accuracy = 9% (36/400)
Accuracy = 10% (40/400)
Accuracy = 8% (32/400)
Accuracy = 8.5% (34/400)
Accuracy = 11.25% (45/400)
Accuracy = 8.75% (35/400)
Load prediction file and append to a list
Get label for x_sub cost 27.0
Substitute data augmentation processing
Augmentation cost 1.4 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Epoch #2:
Current x_sub's size is 800
External call
Accuracy = 8.875% (71/800)
Accuracy = 11.75% (94/800)
Accuracy = 11.125% (89/800)
Accuracy = 10.875% (87/800)
Accuracy = 12.25% (98/800)
Accuracy = 9.5% (76/800)
Accuracy = 10.75% (86/800)
Accuracy = 9.75% (78/800)
Accuracy = 10.5% (84/800)
Accuracy = 11.125% (89/800)
Accuracy = 11.625% (93/800)
Accuracy = 11% (88/800)
Accuracy = 11% (88/800)
Accuracy = 11.875% (95/800)
Accuracy = 9.625% (77/800)
Accuracy = 10.125% (81/800)
Accuracy = 11.125% (89/800)
Accuracy = 10.625% (85/800)
Accuracy = 11.5% (92/800)
Accuracy = 11% (88/800)
Accuracy = 11.625% (93/800)
Accuracy = 10.75% (86/800)
Accuracy = 11.625% (93/800)
Accuracy = 10.875% (87/800)
Accuracy = 11.125% (89/800)
Accuracy = 12% (96/800)
Accuracy = 11.375% (91/800)
Accuracy = 11.875% (95/800)
Accuracy = 10.375% (83/800)
Accuracy = 10% (80/800)
Accuracy = 11.75% (94/800)
Accuracy = 12.25% (98/800)
Accuracy = 10.625% (85/800)
Accuracy = 11.625% (93/800)
Accuracy = 11.375% (91/800)
Accuracy = 10.5% (84/800)
Accuracy = 9.375% (75/800)
Accuracy = 9.75% (78/800)
Accuracy = 9.5% (76/800)
Accuracy = 9.875% (79/800)
Accuracy = 11.125% (89/800)
Accuracy = 12.125% (97/800)
Accuracy = 11.75% (94/800)
Accuracy = 11.5% (92/800)
Accuracy = 10% (80/800)
Accuracy = 11% (88/800)
Accuracy = 10.125% (81/800)
Accuracy = 10.5% (84/800)
Accuracy = 10.875% (87/800)
Accuracy = 11% (88/800)
Accuracy = 10.625% (85/800)
Accuracy = 10.5% (84/800)
Accuracy = 11.5% (92/800)
Accuracy = 11.125% (89/800)
Accuracy = 11.25% (90/800)
Accuracy = 11.875% (95/800)
Accuracy = 11.625% (93/800)
Accuracy = 9.625% (77/800)
Accuracy = 10.75% (86/800)
Accuracy = 10% (80/800)
Accuracy = 10.25% (82/800)
Accuracy = 10.5% (84/800)
Accuracy = 10.625% (85/800)
Accuracy = 10.75% (86/800)
Accuracy = 11.125% (89/800)
Accuracy = 10.75% (86/800)
Accuracy = 10.875% (87/800)
Accuracy = 11.375% (91/800)
Accuracy = 11.125% (89/800)
Accuracy = 9.375% (75/800)
Accuracy = 10.5% (84/800)
Accuracy = 10.75% (86/800)
Accuracy = 11% (88/800)
Accuracy = 10.625% (85/800)
Accuracy = 11.875% (95/800)
Accuracy = 11.625% (93/800)
Accuracy = 10.75% (86/800)
Accuracy = 11.125% (89/800)
Accuracy = 10.875% (87/800)
Accuracy = 11.375% (91/800)
Accuracy = 11.375% (91/800)
Accuracy = 11% (88/800)
Accuracy = 11.125% (89/800)
Accuracy = 11.5% (92/800)
Accuracy = 9.625% (77/800)
Accuracy = 11.875% (95/800)
Accuracy = 11.5% (92/800)
Accuracy = 12.125% (97/800)
Accuracy = 11.5% (92/800)
Accuracy = 11.25% (90/800)
Accuracy = 11.375% (91/800)
Accuracy = 9.875% (79/800)
Accuracy = 11% (88/800)
Accuracy = 11.125% (89/800)
Accuracy = 10.875% (87/800)
Accuracy = 11% (88/800)
Accuracy = 11% (88/800)
Accuracy = 12.75% (102/800)
Accuracy = 10.5% (84/800)
Accuracy = 10% (80/800)
Load prediction file and append to a list
Get label for x_sub cost 47.1
Substitute data augmentation processing
Augmentation cost 2.4 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Oracle model FGSM attack's accuracy on adversarial samples #9800:
External call
Accuracy = 9.62245% (943/9800)
Accuracy = 9.77551% (958/9800)
Accuracy = 9.85714% (966/9800)
Accuracy = 9.37755% (919/9800)
Accuracy = 10.0714% (987/9800)
Accuracy = 9.5102% (932/9800)
Accuracy = 10.2551% (1005/9800)
Accuracy = 9.66327% (947/9800)
Accuracy = 9.82653% (963/9800)
Accuracy = 10.0918% (989/9800)
Accuracy = 9.28571% (910/9800)
Accuracy = 10.3878% (1018/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 10.1633% (996/9800)
Accuracy = 9.87755% (968/9800)
Accuracy = 9.85714% (966/9800)
Accuracy = 9.93878% (974/9800)
Accuracy = 9.79592% (960/9800)
Accuracy = 10.0204% (982/9800)
Accuracy = 9.63265% (944/9800)
Accuracy = 10.3571% (1015/9800)
Accuracy = 10.398% (1019/9800)
Accuracy = 9.7449% (955/9800)
Accuracy = 9.7551% (956/9800)
Accuracy = 9.61224% (942/9800)
Accuracy = 10.2857% (1008/9800)
Accuracy = 10.0918% (989/9800)
Accuracy = 9.92857% (973/9800)
Accuracy = 9.39796% (921/9800)
Accuracy = 9.44898% (926/9800)
Accuracy = 9.7551% (956/9800)
Accuracy = 10.1224% (992/9800)
Accuracy = 10.0816% (988/9800)
Accuracy = 9.76531% (957/9800)
Accuracy = 9.4898% (930/9800)
Accuracy = 9.90816% (971/9800)
Accuracy = 9.47959% (929/9800)
Accuracy = 10.0408% (984/9800)
Accuracy = 9.17347% (899/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 10.5816% (1037/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 9.73469% (954/9800)
Accuracy = 10.0816% (988/9800)
Accuracy = 9.90816% (971/9800)
Accuracy = 9.73469% (954/9800)
Accuracy = 9.87755% (968/9800)
Accuracy = 9.72449% (953/9800)
Accuracy = 9.88776% (969/9800)
Accuracy = 9.90816% (971/9800)
Accuracy = 9.71429% (952/9800)
Accuracy = 9.92857% (973/9800)
Accuracy = 9.60204% (941/9800)
Accuracy = 9.62245% (943/9800)
Accuracy = 10.3061% (1010/9800)
Accuracy = 10.102% (990/9800)
Accuracy = 10.0306% (983/9800)
Accuracy = 9.45918% (927/9800)
Accuracy = 10.1327% (993/9800)
Accuracy = 9.7449% (955/9800)
Accuracy = 10.2653% (1006/9800)
Accuracy = 10.1224% (992/9800)
Accuracy = 9.65306% (946/9800)
Accuracy = 9.57143% (938/9800)
Accuracy = 10.0714% (987/9800)
Accuracy = 10.1327% (993/9800)
Accuracy = 9.26531% (908/9800)
Accuracy = 10.1327% (993/9800)
Accuracy = 10.8673% (1065/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 10.1735% (997/9800)
Accuracy = 10.2347% (1003/9800)
Accuracy = 9.77551% (958/9800)
Accuracy = 10.2449% (1004/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 9.90816% (971/9800)
Accuracy = 10.2857% (1008/9800)
Accuracy = 9.93878% (974/9800)
Accuracy = 9.90816% (971/9800)
Accuracy = 9.44898% (926/9800)
Accuracy = 9.62245% (943/9800)
Accuracy = 9.66327% (947/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 9.76531% (957/9800)
Accuracy = 9.82653% (963/9800)
Accuracy = 9.78571% (959/9800)
Accuracy = 9.83673% (964/9800)
Accuracy = 9.93878% (974/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 9.95918% (976/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 9.90816% (971/9800)
Accuracy = 9.58163% (939/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 9.67347% (948/9800)
Accuracy = 10.2347% (1003/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 9.85714% (966/9800)
Accuracy = 9.83673% (964/9800)
Load prediction file and append to a list
correct_count:  295
Test accuray tensor:  0.03010204081632653
Epoch #3:
Current x_sub's size is 1600
External call
Accuracy = 10.875% (174/1600)
Accuracy = 11.25% (180/1600)
Accuracy = 10.3125% (165/1600)
Accuracy = 10.75% (172/1600)
Accuracy = 10.375% (166/1600)
Accuracy = 10.8125% (173/1600)
Accuracy = 11.0625% (177/1600)
Accuracy = 10.8125% (173/1600)
Accuracy = 10.6875% (171/1600)
Accuracy = 11.4375% (183/1600)
Accuracy = 11.9375% (191/1600)
Accuracy = 9.8125% (157/1600)
Accuracy = 11.125% (178/1600)
Accuracy = 9.9375% (159/1600)
Accuracy = 10.625% (170/1600)
Accuracy = 11.25% (180/1600)
Accuracy = 10.3125% (165/1600)
Accuracy = 10.9375% (175/1600)
Accuracy = 10.9375% (175/1600)
Accuracy = 10.9375% (175/1600)
Accuracy = 10.4375% (167/1600)
Accuracy = 10.875% (174/1600)
Accuracy = 10.75% (172/1600)
Accuracy = 10.625% (170/1600)
Accuracy = 10.1875% (163/1600)
Accuracy = 10.5% (168/1600)
Accuracy = 10.6875% (171/1600)
Accuracy = 10.375% (166/1600)
Accuracy = 9.8125% (157/1600)
Accuracy = 10.75% (172/1600)
Accuracy = 10.4375% (167/1600)
Accuracy = 11.375% (182/1600)
Accuracy = 11.25% (180/1600)
Accuracy = 10.9375% (175/1600)
Accuracy = 10.3125% (165/1600)
Accuracy = 10.375% (166/1600)
Accuracy = 9.5625% (153/1600)
Accuracy = 11.1875% (179/1600)
Accuracy = 10.5% (168/1600)
Accuracy = 11.1875% (179/1600)
Accuracy = 11.125% (178/1600)
Accuracy = 10.5625% (169/1600)
Accuracy = 10.3125% (165/1600)
Accuracy = 11.3125% (181/1600)
Accuracy = 11.0625% (177/1600)
Accuracy = 10.25% (164/1600)
Accuracy = 10.625% (170/1600)
Accuracy = 10.1875% (163/1600)
Accuracy = 10.3125% (165/1600)
Accuracy = 10.8125% (173/1600)
Accuracy = 11.375% (182/1600)
Accuracy = 9.5625% (153/1600)
Accuracy = 11.6875% (187/1600)
Accuracy = 10.5625% (169/1600)
Accuracy = 10.125% (162/1600)
Accuracy = 10.125% (162/1600)
Accuracy = 10.5% (168/1600)
Accuracy = 10.5% (168/1600)
Accuracy = 10.8125% (173/1600)
Accuracy = 10.9375% (175/1600)
Accuracy = 10.8125% (173/1600)
Accuracy = 10.875% (174/1600)
Accuracy = 10.375% (166/1600)
Accuracy = 10.8125% (173/1600)
Accuracy = 10.4375% (167/1600)
Accuracy = 10.5% (168/1600)
Accuracy = 10.9375% (175/1600)
Accuracy = 10.0625% (161/1600)
Accuracy = 10.125% (162/1600)
Accuracy = 10.1875% (163/1600)
Accuracy = 11.0625% (177/1600)
Accuracy = 10.6875% (171/1600)
Accuracy = 11.8125% (189/1600)
Accuracy = 11.125% (178/1600)
Accuracy = 10.0625% (161/1600)
Accuracy = 11.0625% (177/1600)
Accuracy = 10.6875% (171/1600)
Accuracy = 11.0625% (177/1600)
Accuracy = 10.5625% (169/1600)
Accuracy = 10.3125% (165/1600)
Accuracy = 9.5% (152/1600)
Accuracy = 10.9375% (175/1600)
Accuracy = 10.1875% (163/1600)
Accuracy = 12% (192/1600)
Accuracy = 10.5% (168/1600)
Accuracy = 10.6875% (171/1600)
Accuracy = 11.125% (178/1600)
Accuracy = 9.75% (156/1600)
Accuracy = 11.375% (182/1600)
Accuracy = 10.3125% (165/1600)
Accuracy = 10.625% (170/1600)
Accuracy = 11.25% (180/1600)
Accuracy = 11.6875% (187/1600)
Accuracy = 10.3125% (165/1600)
Accuracy = 11.0625% (177/1600)
Accuracy = 10.25% (164/1600)
Accuracy = 10.8125% (173/1600)
Accuracy = 10.3125% (165/1600)
Accuracy = 10.5% (168/1600)
Accuracy = 10.5625% (169/1600)
Load prediction file and append to a list
Get label for x_sub cost 84.4
Substitute data augmentation processing
Augmentation cost 5.0 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Epoch #4:
Current x_sub's size is 3200
External call
Accuracy = 10.4062% (333/3200)
Accuracy = 10.1875% (326/3200)
Accuracy = 10% (320/3200)
Accuracy = 10.375% (332/3200)
Accuracy = 9.9375% (318/3200)
Accuracy = 10.4375% (334/3200)
Accuracy = 10.6562% (341/3200)
Accuracy = 10.2812% (329/3200)
Accuracy = 10.1875% (326/3200)
Accuracy = 9.875% (316/3200)
Accuracy = 10.5625% (338/3200)
Accuracy = 10.6562% (341/3200)
Accuracy = 10.5625% (338/3200)
Accuracy = 10.4375% (334/3200)
Accuracy = 10.6875% (342/3200)
Accuracy = 10.7812% (345/3200)
Accuracy = 10.5312% (337/3200)
Accuracy = 10.875% (348/3200)
Accuracy = 10.375% (332/3200)
Accuracy = 10.6562% (341/3200)
Accuracy = 10.6562% (341/3200)
Accuracy = 10.6562% (341/3200)
Accuracy = 10.5938% (339/3200)
Accuracy = 10.3125% (330/3200)
Accuracy = 10.6875% (342/3200)
Accuracy = 10.4375% (334/3200)
Accuracy = 10.9688% (351/3200)
Accuracy = 10.1875% (326/3200)
Accuracy = 10.3438% (331/3200)
Accuracy = 10.75% (344/3200)
Accuracy = 10.5312% (337/3200)
Accuracy = 10.5312% (337/3200)
Accuracy = 10.25% (328/3200)
Accuracy = 10.625% (340/3200)
Accuracy = 10.2188% (327/3200)
Accuracy = 11.3438% (363/3200)
Accuracy = 10.375% (332/3200)
Accuracy = 10.1875% (326/3200)
Accuracy = 10.375% (332/3200)
Accuracy = 9.90625% (317/3200)
Accuracy = 9.71875% (311/3200)
Accuracy = 10.5938% (339/3200)
Accuracy = 11.1875% (358/3200)
Accuracy = 10.25% (328/3200)
Accuracy = 10.4375% (334/3200)
Accuracy = 10.3438% (331/3200)
Accuracy = 10.6562% (341/3200)
Accuracy = 11.125% (356/3200)
Accuracy = 10.5938% (339/3200)
Accuracy = 10.9375% (350/3200)
Accuracy = 10.2188% (327/3200)
Accuracy = 10.2812% (329/3200)
Accuracy = 10.25% (328/3200)
Accuracy = 11.0625% (354/3200)
Accuracy = 10.5% (336/3200)
Accuracy = 10.5625% (338/3200)
Accuracy = 10.3125% (330/3200)
Accuracy = 10.8438% (347/3200)
Accuracy = 11.125% (356/3200)
Accuracy = 10.6875% (342/3200)
Accuracy = 10.1875% (326/3200)
Accuracy = 10.2188% (327/3200)
Accuracy = 10.7188% (343/3200)
Accuracy = 10.4688% (335/3200)
Accuracy = 10.7188% (343/3200)
Accuracy = 10.9062% (349/3200)
Accuracy = 10.5% (336/3200)
Accuracy = 10.625% (340/3200)
Accuracy = 10.7188% (343/3200)
Accuracy = 9.96875% (319/3200)
Accuracy = 11% (352/3200)
Accuracy = 10.3125% (330/3200)
Accuracy = 10.3125% (330/3200)
Accuracy = 10.7188% (343/3200)
Accuracy = 10.5% (336/3200)
Accuracy = 10.4688% (335/3200)
Accuracy = 11% (352/3200)
Accuracy = 10.9062% (349/3200)
Accuracy = 10.3125% (330/3200)
Accuracy = 10.875% (348/3200)
Accuracy = 10.4375% (334/3200)
Accuracy = 10.7188% (343/3200)
Accuracy = 11.1562% (357/3200)
Accuracy = 10.625% (340/3200)
Accuracy = 10.5938% (339/3200)
Accuracy = 11.375% (364/3200)
Accuracy = 10.5625% (338/3200)
Accuracy = 10.9688% (351/3200)
Accuracy = 10.9375% (350/3200)
Accuracy = 10.4375% (334/3200)
Accuracy = 10.5625% (338/3200)
Accuracy = 10.4688% (335/3200)
Accuracy = 11.1562% (357/3200)
Accuracy = 11.0938% (355/3200)
Accuracy = 10.4062% (333/3200)
Accuracy = 10.9688% (351/3200)
Accuracy = 10.3438% (331/3200)
Accuracy = 11.1562% (357/3200)
Accuracy = 11.0625% (354/3200)
Accuracy = 10.2812% (329/3200)
Load prediction file and append to a list
Get label for x_sub cost 159.7
Substitute data augmentation processing
Augmentation cost 9.9 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Oracle model FGSM attack's accuracy on adversarial samples #9800:
External call
Accuracy = 10.449% (1024/9800)
Accuracy = 10.5714% (1036/9800)
Accuracy = 10.2857% (1008/9800)
Accuracy = 10.2857% (1008/9800)
Accuracy = 10.4082% (1020/9800)
Accuracy = 10.0918% (989/9800)
Accuracy = 10.3265% (1012/9800)
Accuracy = 10.3776% (1017/9800)
Accuracy = 10.602% (1039/9800)
Accuracy = 10.2959% (1009/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 10.7347% (1052/9800)
Accuracy = 10.2551% (1005/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 10.8367% (1062/9800)
Accuracy = 10.4898% (1028/9800)
Accuracy = 10.3061% (1010/9800)
Accuracy = 10.0918% (989/9800)
Accuracy = 10.2041% (1000/9800)
Accuracy = 10.3469% (1014/9800)
Accuracy = 10.5% (1029/9800)
Accuracy = 10.5408% (1033/9800)
Accuracy = 10.0918% (989/9800)
Accuracy = 10.5204% (1031/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 10.1837% (998/9800)
Accuracy = 10.3776% (1017/9800)
Accuracy = 10.3265% (1012/9800)
Accuracy = 10.0306% (983/9800)
Accuracy = 10.398% (1019/9800)
Accuracy = 10.3776% (1017/9800)
Accuracy = 10.3163% (1011/9800)
Accuracy = 10.3571% (1015/9800)
Accuracy = 10.5306% (1032/9800)
Accuracy = 10.5102% (1030/9800)
Accuracy = 10.5408% (1033/9800)
Accuracy = 10.551% (1034/9800)
Accuracy = 10.051% (985/9800)
Accuracy = 10.2449% (1004/9800)
Accuracy = 10.3367% (1013/9800)
Accuracy = 9.92857% (973/9800)
Accuracy = 10.2653% (1006/9800)
Accuracy = 10.2653% (1006/9800)
Accuracy = 10.6429% (1043/9800)
Accuracy = 10.5408% (1033/9800)
Accuracy = 10.5204% (1031/9800)
Accuracy = 10.2959% (1009/9800)
Accuracy = 10.102% (990/9800)
Accuracy = 10.2959% (1009/9800)
Accuracy = 10.1735% (997/9800)
Accuracy = 10.1633% (996/9800)
Accuracy = 10.3265% (1012/9800)
Accuracy = 10.4694% (1026/9800)
Accuracy = 10.4286% (1022/9800)
Accuracy = 10.4796% (1027/9800)
Accuracy = 10.2959% (1009/9800)
Accuracy = 10.4898% (1028/9800)
Accuracy = 10.3878% (1018/9800)
Accuracy = 10.398% (1019/9800)
Accuracy = 10.5714% (1036/9800)
Accuracy = 10.5714% (1036/9800)
Accuracy = 10.0714% (987/9800)
Accuracy = 10.4082% (1020/9800)
Accuracy = 10.3878% (1018/9800)
Accuracy = 10.5306% (1032/9800)
Accuracy = 10.2347% (1003/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 10.0612% (986/9800)
Accuracy = 10.6837% (1047/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 10.4796% (1027/9800)
Accuracy = 10.4796% (1027/9800)
Accuracy = 10.4796% (1027/9800)
Accuracy = 10.6633% (1045/9800)
Accuracy = 10.6735% (1046/9800)
Accuracy = 10.4592% (1025/9800)
Accuracy = 10.1224% (992/9800)
Accuracy = 10.3061% (1010/9800)
Accuracy = 10.2143% (1001/9800)
Accuracy = 10.4592% (1025/9800)
Accuracy = 10.6939% (1048/9800)
Accuracy = 10.3469% (1014/9800)
Accuracy = 10.2143% (1001/9800)
Accuracy = 10.4796% (1027/9800)
Accuracy = 10.6122% (1040/9800)
Accuracy = 10.5612% (1035/9800)
Accuracy = 10.3163% (1011/9800)
Accuracy = 10.1327% (993/9800)
Accuracy = 10.2959% (1009/9800)
Accuracy = 10.2245% (1002/9800)
Accuracy = 10.5714% (1036/9800)
Accuracy = 10.5816% (1037/9800)
Accuracy = 10.3265% (1012/9800)
Accuracy = 10.5816% (1037/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 10.8776% (1066/9800)
Accuracy = 10.4082% (1020/9800)
Accuracy = 10.398% (1019/9800)
Accuracy = 10.4694% (1026/9800)
Accuracy = 10.4286% (1022/9800)
Load prediction file and append to a list
correct_count:  87
Test accuray tensor:  0.008877551020408164
Epoch #5:
Current x_sub's size is 6400
External call
Accuracy = 10.5% (672/6400)
Accuracy = 10.7344% (687/6400)
Accuracy = 11.0312% (706/6400)
Accuracy = 10.5469% (675/6400)
Accuracy = 10.2656% (657/6400)
Accuracy = 10.2812% (658/6400)
Accuracy = 10.5938% (678/6400)
Accuracy = 10.6719% (683/6400)
Accuracy = 11.2031% (717/6400)
Accuracy = 11.1406% (713/6400)
Accuracy = 10.7188% (686/6400)
Accuracy = 10.8281% (693/6400)
Accuracy = 10.5781% (677/6400)
Accuracy = 10.3594% (663/6400)
Accuracy = 9.98438% (639/6400)
Accuracy = 10.2344% (655/6400)
Accuracy = 10.5% (672/6400)
Accuracy = 9.84375% (630/6400)
Accuracy = 10.5625% (676/6400)
Accuracy = 10.3594% (663/6400)
Accuracy = 10.5469% (675/6400)
Accuracy = 10.625% (680/6400)
Accuracy = 10.4375% (668/6400)
Accuracy = 10.8281% (693/6400)
Accuracy = 10.2656% (657/6400)
Accuracy = 10.2969% (659/6400)
Accuracy = 10.3438% (662/6400)
Accuracy = 10.3594% (663/6400)
Accuracy = 10.2656% (657/6400)
Accuracy = 10.75% (688/6400)
Accuracy = 11.0312% (706/6400)
Accuracy = 10.625% (680/6400)
Accuracy = 10.7188% (686/6400)
Accuracy = 10.3594% (663/6400)
Accuracy = 10.125% (648/6400)
Accuracy = 10.9375% (700/6400)
Accuracy = 10.7031% (685/6400)
Accuracy = 10.9531% (701/6400)
Accuracy = 10.0312% (642/6400)
Accuracy = 10.0469% (643/6400)
Accuracy = 10.3438% (662/6400)
Accuracy = 10.6406% (681/6400)
Accuracy = 10.2812% (658/6400)
Accuracy = 10.75% (688/6400)
Accuracy = 10.1562% (650/6400)
Accuracy = 10.1406% (649/6400)
Accuracy = 10.5625% (676/6400)
Accuracy = 10.4375% (668/6400)
Accuracy = 10.125% (648/6400)
Accuracy = 10.4844% (671/6400)
Accuracy = 9.96875% (638/6400)
Accuracy = 10.9062% (698/6400)
Accuracy = 10.4531% (669/6400)
Accuracy = 10.3906% (665/6400)
Accuracy = 9.89062% (633/6400)
Accuracy = 10.3125% (660/6400)
Accuracy = 10.3594% (663/6400)
Accuracy = 10.3125% (660/6400)
Accuracy = 10% (640/6400)
Accuracy = 10.5781% (677/6400)
Accuracy = 9.98438% (639/6400)
Accuracy = 10.3906% (665/6400)
Accuracy = 10.875% (696/6400)
Accuracy = 10.2031% (653/6400)
Accuracy = 10.4375% (668/6400)
Accuracy = 10.2344% (655/6400)
Accuracy = 10.5% (672/6400)
Accuracy = 10.2031% (653/6400)
Accuracy = 10.4062% (666/6400)
Accuracy = 10.75% (688/6400)
Accuracy = 10.4375% (668/6400)
Accuracy = 10.2656% (657/6400)
Accuracy = 9.98438% (639/6400)
Accuracy = 10.8281% (693/6400)
Accuracy = 10.5156% (673/6400)
Accuracy = 10.7656% (689/6400)
Accuracy = 10.4844% (671/6400)
Accuracy = 9.89062% (633/6400)
Accuracy = 10.2031% (653/6400)
Accuracy = 10.7812% (690/6400)
Accuracy = 10.2031% (653/6400)
Accuracy = 10.875% (696/6400)
Accuracy = 10.4219% (667/6400)
Accuracy = 10.6406% (681/6400)
Accuracy = 10.2812% (658/6400)
Accuracy = 10.4688% (670/6400)
Accuracy = 10.5156% (673/6400)
Accuracy = 10.4844% (671/6400)
Accuracy = 10.7656% (689/6400)
Accuracy = 9.98438% (639/6400)
Accuracy = 10.6875% (684/6400)
Accuracy = 10.375% (664/6400)
Accuracy = 10.3438% (662/6400)
Accuracy = 10.6719% (683/6400)
Accuracy = 10.1719% (651/6400)
Accuracy = 10.8906% (697/6400)
Accuracy = 10.375% (664/6400)
Accuracy = 10.5312% (674/6400)
Accuracy = 10.6875% (684/6400)
Accuracy = 10.2812% (658/6400)
Load prediction file and append to a list
Get label for x_sub cost 314.2
Substitute data augmentation processing
Augmentation cost 19.3 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Epoch #6:
Current x_sub's size is 12800
External call
Accuracy = 10.3281% (1322/12800)
Accuracy = 10.0547% (1287/12800)
Accuracy = 10.4922% (1343/12800)
Accuracy = 10.0312% (1284/12800)
Accuracy = 10.4141% (1333/12800)
Accuracy = 10.1094% (1294/12800)
Accuracy = 9.8125% (1256/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 10.3984% (1331/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.3125% (1320/12800)
Accuracy = 10.2266% (1309/12800)
Accuracy = 10.2656% (1314/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 10.2812% (1316/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 10.2344% (1310/12800)
Accuracy = 10.1797% (1303/12800)
Accuracy = 10.4062% (1332/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.1406% (1298/12800)
Accuracy = 10.1719% (1302/12800)
Accuracy = 10.0391% (1285/12800)
Accuracy = 10.375% (1328/12800)
Accuracy = 10.1797% (1303/12800)
Accuracy = 10.2812% (1316/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 10.6875% (1368/12800)
Accuracy = 10.3359% (1323/12800)
Accuracy = 9.98438% (1278/12800)
Accuracy = 10.5078% (1345/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 10.4141% (1333/12800)
Accuracy = 10.3125% (1320/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 10.5625% (1352/12800)
Accuracy = 10.2656% (1314/12800)
Accuracy = 10.2109% (1307/12800)
Accuracy = 9.95312% (1274/12800)
Accuracy = 10.4375% (1336/12800)
Accuracy = 10.3594% (1326/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 10.1797% (1303/12800)
Accuracy = 10.5625% (1352/12800)
Accuracy = 10.3125% (1320/12800)
Accuracy = 10.1406% (1298/12800)
Accuracy = 10.4453% (1337/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.7188% (1372/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 10.125% (1296/12800)
Accuracy = 10.4609% (1339/12800)
Accuracy = 10.375% (1328/12800)
Accuracy = 10.0625% (1288/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 10.3828% (1329/12800)
Accuracy = 10.5312% (1348/12800)
Accuracy = 10.0391% (1285/12800)
Accuracy = 10.2891% (1317/12800)
Accuracy = 9.8125% (1256/12800)
Accuracy = 10.0391% (1285/12800)
Accuracy = 10.7422% (1375/12800)
Accuracy = 10.0938% (1292/12800)
Accuracy = 10.0625% (1288/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 10.2422% (1311/12800)
Accuracy = 10.2266% (1309/12800)
Accuracy = 10.2188% (1308/12800)
Accuracy = 10.2188% (1308/12800)
Accuracy = 10.2422% (1311/12800)
Accuracy = 10.4766% (1341/12800)
Accuracy = 10.2109% (1307/12800)
Accuracy = 9.9375% (1272/12800)
Accuracy = 10.4609% (1339/12800)
Accuracy = 10.0625% (1288/12800)
Accuracy = 9.95312% (1274/12800)
Accuracy = 9.82031% (1257/12800)
Accuracy = 10.4844% (1342/12800)
Accuracy = 10.2188% (1308/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 10.3281% (1322/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 10.0625% (1288/12800)
Accuracy = 10.1406% (1298/12800)
Accuracy = 10.2891% (1317/12800)
Accuracy = 10.4922% (1343/12800)
Accuracy = 10.3203% (1321/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 10.0391% (1285/12800)
Accuracy = 10.0938% (1292/12800)
Accuracy = 10.3828% (1329/12800)
Accuracy = 10.0781% (1290/12800)
Accuracy = 10.3594% (1326/12800)
Accuracy = 10.3516% (1325/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 10.0625% (1288/12800)
Accuracy = 10.25% (1312/12800)
Load prediction file and append to a list
Get label for x_sub cost 647.2
Substitute data augmentation processing
Augmentation cost 38.2 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Oracle model FGSM attack's accuracy on adversarial samples #9800:
External call
Accuracy = 9.80612% (961/9800)
Accuracy = 9.7551% (956/9800)
Accuracy = 9.63265% (944/9800)
Accuracy = 9.62245% (943/9800)
Accuracy = 9.61224% (942/9800)
Accuracy = 9.46939% (928/9800)
Accuracy = 10.0714% (987/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 9.7551% (956/9800)
Accuracy = 9.7551% (956/9800)
Accuracy = 9.91837% (972/9800)
Accuracy = 9.73469% (954/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 9.82653% (963/9800)
Accuracy = 9.7449% (955/9800)
Accuracy = 9.73469% (954/9800)
Accuracy = 9.86735% (967/9800)
Accuracy = 9.92857% (973/9800)
Accuracy = 9.63265% (944/9800)
Accuracy = 10.0306% (983/9800)
Accuracy = 9.81633% (962/9800)
Accuracy = 9.81633% (962/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 9.72449% (953/9800)
Accuracy = 10.0102% (981/9800)
Accuracy = 9.73469% (954/9800)
Accuracy = 9.71429% (952/9800)
Accuracy = 9.73469% (954/9800)
Accuracy = 9.37755% (919/9800)
Accuracy = 9.64286% (945/9800)
Accuracy = 9.93878% (974/9800)
Accuracy = 9.73469% (954/9800)
Accuracy = 9.59184% (940/9800)
Accuracy = 9.83673% (964/9800)
Accuracy = 9.80612% (961/9800)
Accuracy = 9.78571% (959/9800)
Accuracy = 10.1429% (994/9800)
Accuracy = 9.71429% (952/9800)
Accuracy = 9.87755% (968/9800)
Accuracy = 9.67347% (948/9800)
Accuracy = 9.71429% (952/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 9.80612% (961/9800)
Accuracy = 9.68367% (949/9800)
Accuracy = 9.69388% (950/9800)
Accuracy = 9.82653% (963/9800)
Accuracy = 9.72449% (953/9800)
Accuracy = 9.59184% (940/9800)
Accuracy = 9.7551% (956/9800)
Accuracy = 9.92857% (973/9800)
Accuracy = 10.0714% (987/9800)
Accuracy = 9.69388% (950/9800)
Accuracy = 9.42857% (924/9800)
Accuracy = 9.67347% (948/9800)
Accuracy = 9.63265% (944/9800)
Accuracy = 9.64286% (945/9800)
Accuracy = 9.92857% (973/9800)
Accuracy = 9.95918% (976/9800)
Accuracy = 9.27551% (909/9800)
Accuracy = 9.86735% (967/9800)
Accuracy = 9.90816% (971/9800)
Accuracy = 9.71429% (952/9800)
Accuracy = 9.80612% (961/9800)
Accuracy = 10.051% (985/9800)
Accuracy = 9.67347% (948/9800)
Accuracy = 9.65306% (946/9800)
Accuracy = 9.76531% (957/9800)
Accuracy = 9.54082% (935/9800)
Accuracy = 9.82653% (963/9800)
Accuracy = 9.70408% (951/9800)
Accuracy = 9.76531% (957/9800)
Accuracy = 10.0816% (988/9800)
Accuracy = 9.77551% (958/9800)
Accuracy = 9.80612% (961/9800)
Accuracy = 9.81633% (962/9800)
Accuracy = 9.57143% (938/9800)
Accuracy = 9.91837% (972/9800)
Accuracy = 9.77551% (958/9800)
Accuracy = 9.85714% (966/9800)
Accuracy = 9.57143% (938/9800)
Accuracy = 9.73469% (954/9800)
Accuracy = 9.63265% (944/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 9.87755% (968/9800)
Accuracy = 9.94898% (975/9800)
Accuracy = 9.56122% (937/9800)
Accuracy = 9.83673% (964/9800)
Accuracy = 10.1735% (997/9800)
Accuracy = 10.2347% (1003/9800)
Accuracy = 9.91837% (972/9800)
Accuracy = 9.7449% (955/9800)
Accuracy = 9.82653% (963/9800)
Accuracy = 9.90816% (971/9800)
Accuracy = 9.90816% (971/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 9.95918% (976/9800)
Accuracy = 9.78571% (959/9800)
Accuracy = 9.88776% (969/9800)
Accuracy = 9.73469% (954/9800)
Accuracy = 9.82653% (963/9800)
Load prediction file and append to a list
correct_count:  0
Test accuray tensor:  0.0
Epoch #7:
Current x_sub's size is 12800
External call
Accuracy = 10.2969% (1318/12800)
Accuracy = 10.125% (1296/12800)
Accuracy = 9.67188% (1238/12800)
Accuracy = 9.78125% (1252/12800)
Accuracy = 10.0547% (1287/12800)
Accuracy = 10.0547% (1287/12800)
Accuracy = 10.2188% (1308/12800)
Accuracy = 9.72656% (1245/12800)
Accuracy = 9.82031% (1257/12800)
Accuracy = 10.2969% (1318/12800)
Accuracy = 9.82812% (1258/12800)
Accuracy = 9.77344% (1251/12800)
Accuracy = 10.0625% (1288/12800)
Accuracy = 10.0469% (1286/12800)
Accuracy = 9.89062% (1266/12800)
Accuracy = 10% (1280/12800)
Accuracy = 10.1328% (1297/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 10.0391% (1285/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 9.8125% (1256/12800)
Accuracy = 9.75% (1248/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 10.0391% (1285/12800)
Accuracy = 10.125% (1296/12800)
Accuracy = 9.85938% (1262/12800)
Accuracy = 10.0625% (1288/12800)
Accuracy = 10.1484% (1299/12800)
Accuracy = 10.0703% (1289/12800)
Accuracy = 10.2344% (1310/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 10.2266% (1309/12800)
Accuracy = 10.1016% (1293/12800)
Accuracy = 10% (1280/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 10.1797% (1303/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 10.2422% (1311/12800)
Accuracy = 10.0156% (1282/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 9.90625% (1268/12800)
Accuracy = 10.125% (1296/12800)
Accuracy = 10.0625% (1288/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 9.98438% (1278/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 9.99219% (1279/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 9.96094% (1275/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.90625% (1268/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 9.95312% (1274/12800)
Accuracy = 10.1328% (1297/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 10.4062% (1332/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 10.1719% (1302/12800)
Accuracy = 10.1719% (1302/12800)
Accuracy = 10.2656% (1314/12800)
Accuracy = 10.1016% (1293/12800)
Accuracy = 9.90625% (1268/12800)
Accuracy = 9.96094% (1275/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 10.3125% (1320/12800)
Accuracy = 10.0469% (1286/12800)
Accuracy = 10.1641% (1301/12800)
Accuracy = 10.0938% (1292/12800)
Accuracy = 9.84375% (1260/12800)
Accuracy = 9.96094% (1275/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 10.2188% (1308/12800)
Accuracy = 10.0391% (1285/12800)
Accuracy = 9.9375% (1272/12800)
Accuracy = 10.0938% (1292/12800)
Accuracy = 10.1875% (1304/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 10.0938% (1292/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 10.0391% (1285/12800)
Accuracy = 10.0156% (1282/12800)
Accuracy = 10.0156% (1282/12800)
Accuracy = 10.125% (1296/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 9.72656% (1245/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 9.95312% (1274/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 9.77344% (1251/12800)
Accuracy = 10.0156% (1282/12800)
Accuracy = 9.89062% (1266/12800)
Accuracy = 10.1875% (1304/12800)
Accuracy = 10.1562% (1300/12800)
Load prediction file and append to a list
Get label for x_sub cost 635.4
Substitute data augmentation processing
Augmentation cost 38.8 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Epoch #8:
Current x_sub's size is 12800
External call
Accuracy = 10.1094% (1294/12800)
Accuracy = 10.2578% (1313/12800)
Accuracy = 10.4219% (1334/12800)
Accuracy = 10.0781% (1290/12800)
Accuracy = 10.4062% (1332/12800)
Accuracy = 10.4062% (1332/12800)
Accuracy = 10.3984% (1331/12800)
Accuracy = 10.2422% (1311/12800)
Accuracy = 10.1875% (1304/12800)
Accuracy = 10.4375% (1336/12800)
Accuracy = 10.1328% (1297/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 10.2812% (1316/12800)
Accuracy = 10.4922% (1343/12800)
Accuracy = 10.0781% (1290/12800)
Accuracy = 10.6719% (1366/12800)
Accuracy = 10.1641% (1301/12800)
Accuracy = 9.625% (1232/12800)
Accuracy = 10.0703% (1289/12800)
Accuracy = 10.3125% (1320/12800)
Accuracy = 10.2734% (1315/12800)
Accuracy = 10.1016% (1293/12800)
Accuracy = 10.3672% (1327/12800)
Accuracy = 10.3594% (1326/12800)
Accuracy = 10.1797% (1303/12800)
Accuracy = 10.1094% (1294/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 10.3984% (1331/12800)
Accuracy = 9.96094% (1275/12800)
Accuracy = 10.1016% (1293/12800)
Accuracy = 10.2734% (1315/12800)
Accuracy = 10.1875% (1304/12800)
Accuracy = 9.82812% (1258/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 10.3438% (1324/12800)
Accuracy = 9.91406% (1269/12800)
Accuracy = 9.79688% (1254/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 10.2734% (1315/12800)
Accuracy = 10.4531% (1338/12800)
Accuracy = 10.3984% (1331/12800)
Accuracy = 10.0625% (1288/12800)
Accuracy = 10.1016% (1293/12800)
Accuracy = 10.4688% (1340/12800)
Accuracy = 10.1875% (1304/12800)
Accuracy = 10.2578% (1313/12800)
Accuracy = 10.4219% (1334/12800)
Accuracy = 10.1484% (1299/12800)
Accuracy = 10.2969% (1318/12800)
Accuracy = 10.4219% (1334/12800)
Accuracy = 10.1719% (1302/12800)
Accuracy = 10.0391% (1285/12800)
Accuracy = 10.1797% (1303/12800)
Accuracy = 10.4062% (1332/12800)
Accuracy = 10.0625% (1288/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 9.74219% (1247/12800)
Accuracy = 10.1641% (1301/12800)
Accuracy = 10.3906% (1330/12800)
Accuracy = 9.80469% (1255/12800)
Accuracy = 10.4375% (1336/12800)
Accuracy = 10.4141% (1333/12800)
Accuracy = 10.2812% (1316/12800)
Accuracy = 10.4062% (1332/12800)
Accuracy = 10.4062% (1332/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 10.1016% (1293/12800)
Accuracy = 10.4844% (1342/12800)
Accuracy = 10.4453% (1337/12800)
Accuracy = 10.1094% (1294/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 10.0469% (1286/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 10.6406% (1362/12800)
Accuracy = 10.2188% (1308/12800)
Accuracy = 10.1016% (1293/12800)
Accuracy = 10.2734% (1315/12800)
Accuracy = 10.0703% (1289/12800)
Accuracy = 10.3438% (1324/12800)
Accuracy = 10.4531% (1338/12800)
Accuracy = 10.3828% (1329/12800)
Accuracy = 10.5312% (1348/12800)
Accuracy = 10.6016% (1357/12800)
Accuracy = 10.0156% (1282/12800)
Accuracy = 9.96094% (1275/12800)
Accuracy = 10.3984% (1331/12800)
Accuracy = 10.5859% (1355/12800)
Accuracy = 10.0469% (1286/12800)
Accuracy = 10.1875% (1304/12800)
Accuracy = 10.7578% (1377/12800)
Accuracy = 10.2734% (1315/12800)
Accuracy = 10.0156% (1282/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 10.5312% (1348/12800)
Accuracy = 10.4062% (1332/12800)
Accuracy = 10.0547% (1287/12800)
Accuracy = 10.3203% (1321/12800)
Accuracy = 9.99219% (1279/12800)
Accuracy = 10.1875% (1304/12800)
Load prediction file and append to a list
Get label for x_sub cost 627.7
Substitute data augmentation processing
Augmentation cost 38.2 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Oracle model FGSM attack's accuracy on adversarial samples #9800:
External call
Accuracy = 9.28571% (910/9800)
Accuracy = 9.7449% (955/9800)
Accuracy = 9.77551% (958/9800)
Accuracy = 9.7449% (955/9800)
Accuracy = 9.64286% (945/9800)
Accuracy = 9.5% (931/9800)
Accuracy = 9.64286% (945/9800)
Accuracy = 9.83673% (964/9800)
Accuracy = 9.55102% (936/9800)
Accuracy = 9.65306% (946/9800)
Accuracy = 9.54082% (935/9800)
Accuracy = 10.102% (990/9800)
Accuracy = 9.52041% (933/9800)
Accuracy = 9.44898% (926/9800)
Accuracy = 10.4898% (1028/9800)
Accuracy = 9.69388% (950/9800)
Accuracy = 9.79592% (960/9800)
Accuracy = 9.92857% (973/9800)
Accuracy = 9.86735% (967/9800)
Accuracy = 9.31633% (913/9800)
Accuracy = 9.7551% (956/9800)
Accuracy = 9.72449% (953/9800)
Accuracy = 9.55102% (936/9800)
Accuracy = 9.52041% (933/9800)
Accuracy = 9.34694% (916/9800)
Accuracy = 9.7551% (956/9800)
Accuracy = 9.42857% (924/9800)
Accuracy = 9.72449% (953/9800)
Accuracy = 10% (980/9800)
Accuracy = 9.55102% (936/9800)
Accuracy = 9.5% (931/9800)
Accuracy = 9.77551% (958/9800)
Accuracy = 9.78571% (959/9800)
Accuracy = 9.46939% (928/9800)
Accuracy = 9.67347% (948/9800)
Accuracy = 9.66327% (947/9800)
Accuracy = 10.6122% (1040/9800)
Accuracy = 9.65306% (946/9800)
Accuracy = 10.1531% (995/9800)
Accuracy = 9.60204% (941/9800)
Accuracy = 9.72449% (953/9800)
Accuracy = 9.42857% (924/9800)
Accuracy = 9.5% (931/9800)
Accuracy = 9.69388% (950/9800)
Accuracy = 9.69388% (950/9800)
Accuracy = 9.91837% (972/9800)
Accuracy = 9.44898% (926/9800)
Accuracy = 9.64286% (945/9800)
Accuracy = 9.55102% (936/9800)
Accuracy = 9.72449% (953/9800)
Accuracy = 9.62245% (943/9800)
Accuracy = 9.68367% (949/9800)
Accuracy = 9.54082% (935/9800)
Accuracy = 9.4898% (930/9800)
Accuracy = 9.57143% (938/9800)
Accuracy = 9.56122% (937/9800)
Accuracy = 9.37755% (919/9800)
Accuracy = 10.3673% (1016/9800)
Accuracy = 9.57143% (938/9800)
Accuracy = 9.31633% (913/9800)
Accuracy = 9.44898% (926/9800)
Accuracy = 9.57143% (938/9800)
Accuracy = 9.46939% (928/9800)
Accuracy = 9.5102% (932/9800)
Accuracy = 9.52041% (933/9800)
Accuracy = 9.5102% (932/9800)
Accuracy = 10.2041% (1000/9800)
Accuracy = 9.56122% (937/9800)
Accuracy = 9.58163% (939/9800)
Accuracy = 9.72449% (953/9800)
Accuracy = 9.40816% (922/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 9.59184% (940/9800)
Accuracy = 9.4898% (930/9800)
Accuracy = 9.64286% (945/9800)
Accuracy = 9.60204% (941/9800)
Accuracy = 9.57143% (938/9800)
Accuracy = 10.1327% (993/9800)
Accuracy = 9.78571% (959/9800)
Accuracy = 9.43878% (925/9800)
Accuracy = 9.68367% (949/9800)
Accuracy = 9.65306% (946/9800)
Accuracy = 9.64286% (945/9800)
Accuracy = 9.61224% (942/9800)
Accuracy = 9.86735% (967/9800)
Accuracy = 9.52041% (933/9800)
Accuracy = 9.42857% (924/9800)
Accuracy = 9.64286% (945/9800)
Accuracy = 9.43878% (925/9800)
Accuracy = 10.398% (1019/9800)
Accuracy = 9.47959% (929/9800)
Accuracy = 9.4898% (930/9800)
Accuracy = 9.73469% (954/9800)
Accuracy = 9.78571% (959/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 9.54082% (935/9800)
Accuracy = 9.71429% (952/9800)
Accuracy = 9.66327% (947/9800)
Accuracy = 9.54082% (935/9800)
Accuracy = 9.7551% (956/9800)
Load prediction file and append to a list
correct_count:  0
Test accuray tensor:  0.0
Epoch #9:
Current x_sub's size is 12800
External call
Accuracy = 10.2422% (1311/12800)
Accuracy = 10.3047% (1319/12800)
Accuracy = 10.3906% (1330/12800)
Accuracy = 10.125% (1296/12800)
Accuracy = 10.2656% (1314/12800)
Accuracy = 10.2422% (1311/12800)
Accuracy = 10.3125% (1320/12800)
Accuracy = 10.0156% (1282/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.3438% (1324/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.3047% (1319/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.2734% (1315/12800)
Accuracy = 10.0625% (1288/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.3516% (1325/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.3516% (1325/12800)
Accuracy = 10.3281% (1322/12800)
Accuracy = 10.4297% (1335/12800)
Accuracy = 10.2109% (1307/12800)
Accuracy = 10.3594% (1326/12800)
Accuracy = 10.2734% (1315/12800)
Accuracy = 10.1875% (1304/12800)
Accuracy = 10.2812% (1316/12800)
Accuracy = 10.3672% (1327/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.2578% (1313/12800)
Accuracy = 10.1328% (1297/12800)
Accuracy = 10.2578% (1313/12800)
Accuracy = 10.2656% (1314/12800)
Accuracy = 10.1641% (1301/12800)
Accuracy = 10.3594% (1326/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 10.4453% (1337/12800)
Accuracy = 10.2656% (1314/12800)
Accuracy = 10.375% (1328/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 10.2188% (1308/12800)
Accuracy = 10.3125% (1320/12800)
Accuracy = 10.2891% (1317/12800)
Accuracy = 10.2266% (1309/12800)
Accuracy = 10.1016% (1293/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.2656% (1314/12800)
Accuracy = 10.3203% (1321/12800)
Accuracy = 10.2578% (1313/12800)
Accuracy = 10.1328% (1297/12800)
Accuracy = 10.2656% (1314/12800)
Accuracy = 10.2734% (1315/12800)
Accuracy = 10.2578% (1313/12800)
Accuracy = 10.2578% (1313/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 10.5781% (1354/12800)
Accuracy = 10.3672% (1327/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 10.2422% (1311/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.375% (1328/12800)
Accuracy = 10.2109% (1307/12800)
Accuracy = 10.2891% (1317/12800)
Accuracy = 10.2188% (1308/12800)
Accuracy = 10.25% (1312/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 10.1641% (1301/12800)
Accuracy = 10.1797% (1303/12800)
Accuracy = 10.4062% (1332/12800)
Accuracy = 10.2422% (1311/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 10.2188% (1308/12800)
Accuracy = 10.4375% (1336/12800)
Accuracy = 10.0781% (1290/12800)
Accuracy = 10.1719% (1302/12800)
Accuracy = 10.2656% (1314/12800)
Accuracy = 10.2969% (1318/12800)
Accuracy = 10.2578% (1313/12800)
Accuracy = 10.2812% (1316/12800)
Accuracy = 10.3203% (1321/12800)
Accuracy = 10.3125% (1320/12800)
Accuracy = 10.4531% (1338/12800)
Accuracy = 10.2109% (1307/12800)
Accuracy = 10.1484% (1299/12800)
Accuracy = 10.3125% (1320/12800)
Accuracy = 10.25% (1312/12800)
Accuracy = 10.1094% (1294/12800)
Accuracy = 10.1719% (1302/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.2344% (1310/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 10.1875% (1304/12800)
Accuracy = 10.1484% (1299/12800)
Accuracy = 10.1641% (1301/12800)
Accuracy = 10.375% (1328/12800)
Accuracy = 10.4219% (1334/12800)
Load prediction file and append to a list
Get label for x_sub cost 619.8
Substitute data augmentation processing
Augmentation cost 31.7 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Epoch #10:
Current x_sub's size is 12800
External call
Accuracy = 9.96094% (1275/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 9.84375% (1260/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 9.90625% (1268/12800)
Accuracy = 9.8125% (1256/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 9.5625% (1224/12800)
Accuracy = 9.77344% (1251/12800)
Accuracy = 9.8125% (1256/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 10.0703% (1289/12800)
Accuracy = 9.79688% (1254/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 9.99219% (1279/12800)
Accuracy = 9.76562% (1250/12800)
Accuracy = 9.90625% (1268/12800)
Accuracy = 9.82031% (1257/12800)
Accuracy = 9.95312% (1274/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.91406% (1269/12800)
Accuracy = 9.84375% (1260/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 9.90625% (1268/12800)
Accuracy = 9.80469% (1255/12800)
Accuracy = 9.95312% (1274/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 9.85938% (1262/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 9.82031% (1257/12800)
Accuracy = 9.9375% (1272/12800)
Accuracy = 9.66406% (1237/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 9.91406% (1269/12800)
Accuracy = 9.83594% (1259/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 9.99219% (1279/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.9375% (1272/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 9.82812% (1258/12800)
Accuracy = 9.9375% (1272/12800)
Accuracy = 9.90625% (1268/12800)
Accuracy = 9.8125% (1256/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.96094% (1275/12800)
Accuracy = 10.0469% (1286/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.90625% (1268/12800)
Accuracy = 9.91406% (1269/12800)
Accuracy = 9.91406% (1269/12800)
Accuracy = 10.1094% (1294/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 9.82031% (1257/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 9.84375% (1260/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 10.0156% (1282/12800)
Accuracy = 9.80469% (1255/12800)
Accuracy = 9.89062% (1266/12800)
Accuracy = 9.78125% (1252/12800)
Accuracy = 9.77344% (1251/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.83594% (1259/12800)
Accuracy = 9.90625% (1268/12800)
Accuracy = 9.95312% (1274/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 9.78125% (1252/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.78906% (1253/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 9.90625% (1268/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 9.82812% (1258/12800)
Accuracy = 9.84375% (1260/12800)
Accuracy = 9.98438% (1278/12800)
Accuracy = 9.9375% (1272/12800)
Load prediction file and append to a list
Get label for x_sub cost 614.5
Substitute data augmentation processing
Augmentation cost 31.6 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Oracle model FGSM attack's accuracy on adversarial samples #9800:
External call
Accuracy = 10.5204% (1031/9800)
Accuracy = 10.3878% (1018/9800)
Accuracy = 10.602% (1039/9800)
Accuracy = 10.5% (1029/9800)
Accuracy = 10.6224% (1041/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 10.3061% (1010/9800)
Accuracy = 10.3367% (1013/9800)
Accuracy = 10.1633% (996/9800)
Accuracy = 10.2245% (1002/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 10.5816% (1037/9800)
Accuracy = 10.4184% (1021/9800)
Accuracy = 10.3061% (1010/9800)
Accuracy = 10.2959% (1009/9800)
Accuracy = 10.1224% (992/9800)
Accuracy = 10.4082% (1020/9800)
Accuracy = 10.3367% (1013/9800)
Accuracy = 10.3367% (1013/9800)
Accuracy = 10% (980/9800)
Accuracy = 10.1531% (995/9800)
Accuracy = 10.5408% (1033/9800)
Accuracy = 10.398% (1019/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 10.4694% (1026/9800)
Accuracy = 10.3367% (1013/9800)
Accuracy = 10.1735% (997/9800)
Accuracy = 10.4592% (1025/9800)
Accuracy = 10.6327% (1042/9800)
Accuracy = 10.551% (1034/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 10.2041% (1000/9800)
Accuracy = 10.3061% (1010/9800)
Accuracy = 10.4082% (1020/9800)
Accuracy = 10.5612% (1035/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 10.6224% (1041/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 10.3265% (1012/9800)
Accuracy = 10.3878% (1018/9800)
Accuracy = 10.5306% (1032/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 10.1633% (996/9800)
Accuracy = 10.5102% (1030/9800)
Accuracy = 10.5% (1029/9800)
Accuracy = 10.2551% (1005/9800)
Accuracy = 10.0306% (983/9800)
Accuracy = 10.1735% (997/9800)
Accuracy = 10.4184% (1021/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 10.1633% (996/9800)
Accuracy = 10.2653% (1006/9800)
Accuracy = 10.0612% (986/9800)
Accuracy = 10.398% (1019/9800)
Accuracy = 10.5714% (1036/9800)
Accuracy = 10.2245% (1002/9800)
Accuracy = 10.3061% (1010/9800)
Accuracy = 10.2143% (1001/9800)
Accuracy = 10.4796% (1027/9800)
Accuracy = 10.5714% (1036/9800)
Accuracy = 10.2857% (1008/9800)
Accuracy = 10.2143% (1001/9800)
Accuracy = 10.2449% (1004/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 10.3878% (1018/9800)
Accuracy = 10.6735% (1046/9800)
Accuracy = 10.3061% (1010/9800)
Accuracy = 10.4796% (1027/9800)
Accuracy = 10.4592% (1025/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 10.5306% (1032/9800)
Accuracy = 10.602% (1039/9800)
Accuracy = 10.2653% (1006/9800)
Accuracy = 10.4184% (1021/9800)
Accuracy = 10.2449% (1004/9800)
Accuracy = 10.4898% (1028/9800)
Accuracy = 10.3265% (1012/9800)
Accuracy = 10.5408% (1033/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 10.5102% (1030/9800)
Accuracy = 10.1633% (996/9800)
Accuracy = 10.2857% (1008/9800)
Accuracy = 10.1327% (993/9800)
Accuracy = 10.5918% (1038/9800)
Accuracy = 10.2245% (1002/9800)
Accuracy = 10.1837% (998/9800)
Accuracy = 10.3163% (1011/9800)
Accuracy = 10.2857% (1008/9800)
Accuracy = 10.3061% (1010/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 10.5102% (1030/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 10.4388% (1023/9800)
Accuracy = 10.4694% (1026/9800)
Accuracy = 10.3469% (1014/9800)
Accuracy = 10.4796% (1027/9800)
Accuracy = 10.3673% (1016/9800)
Accuracy = 10.3878% (1018/9800)
Accuracy = 10.398% (1019/9800)
Load prediction file and append to a list
correct_count:  0
Test accuray tensor:  0.0
Epoch #11:
Current x_sub's size is 12800
External call
Accuracy = 10.2656% (1314/12800)
Accuracy = 10.1406% (1298/12800)
Accuracy = 10.1875% (1304/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 10.1719% (1302/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.2656% (1314/12800)
Accuracy = 10.1406% (1298/12800)
Accuracy = 10.3281% (1322/12800)
Accuracy = 10.0391% (1285/12800)
Accuracy = 10.1875% (1304/12800)
Accuracy = 10.1875% (1304/12800)
Accuracy = 10.2344% (1310/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 10.2656% (1314/12800)
Accuracy = 10.2578% (1313/12800)
Accuracy = 10.2188% (1308/12800)
Accuracy = 10.2422% (1311/12800)
Accuracy = 10.2344% (1310/12800)
Accuracy = 10.1641% (1301/12800)
Accuracy = 10.1406% (1298/12800)
Accuracy = 10.1797% (1303/12800)
Accuracy = 10.1641% (1301/12800)
Accuracy = 10.1641% (1301/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.2578% (1313/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 10.0938% (1292/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.1641% (1301/12800)
Accuracy = 10.1328% (1297/12800)
Accuracy = 10.2578% (1313/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.0469% (1286/12800)
Accuracy = 10.2109% (1307/12800)
Accuracy = 10.2969% (1318/12800)
Accuracy = 10.0625% (1288/12800)
Accuracy = 10.2266% (1309/12800)
Accuracy = 10.0703% (1289/12800)
Accuracy = 10.2344% (1310/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 10.2266% (1309/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.2344% (1310/12800)
Accuracy = 10.2891% (1317/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.2188% (1308/12800)
Accuracy = 10.0391% (1285/12800)
Accuracy = 10.1016% (1293/12800)
Accuracy = 10.1641% (1301/12800)
Accuracy = 10.1016% (1293/12800)
Accuracy = 10.2109% (1307/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.1484% (1299/12800)
Accuracy = 10.125% (1296/12800)
Accuracy = 10.2109% (1307/12800)
Accuracy = 10.1797% (1303/12800)
Accuracy = 10.1719% (1302/12800)
Accuracy = 10.1719% (1302/12800)
Accuracy = 10.3438% (1324/12800)
Accuracy = 10.3047% (1319/12800)
Accuracy = 10.1875% (1304/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.3047% (1319/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 10.1016% (1293/12800)
Accuracy = 10.1641% (1301/12800)
Accuracy = 10.2578% (1313/12800)
Accuracy = 10.125% (1296/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 10.2109% (1307/12800)
Accuracy = 10.2656% (1314/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 10.25% (1312/12800)
Accuracy = 10.2812% (1316/12800)
Accuracy = 10.1406% (1298/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 10.1797% (1303/12800)
Accuracy = 10.1875% (1304/12800)
Accuracy = 10.2734% (1315/12800)
Accuracy = 10.1797% (1303/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 10.1719% (1302/12800)
Accuracy = 10.2109% (1307/12800)
Accuracy = 10.1328% (1297/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 10.0938% (1292/12800)
Accuracy = 10.2188% (1308/12800)
Accuracy = 10.2578% (1313/12800)
Accuracy = 10.1094% (1294/12800)
Load prediction file and append to a list
Get label for x_sub cost 617.6
Substitute data augmentation processing
Augmentation cost 32.5 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Epoch #12:
Current x_sub's size is 12800
External call
Accuracy = 9.73438% (1246/12800)
Accuracy = 10.1016% (1293/12800)
Accuracy = 10.0312% (1284/12800)
Accuracy = 9.9375% (1272/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 10.0547% (1287/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 10.1016% (1293/12800)
Accuracy = 10.1875% (1304/12800)
Accuracy = 9.98438% (1278/12800)
Accuracy = 10.0156% (1282/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 10.2734% (1315/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 9.99219% (1279/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 10.0391% (1285/12800)
Accuracy = 9.78125% (1252/12800)
Accuracy = 9.82812% (1258/12800)
Accuracy = 9.98438% (1278/12800)
Accuracy = 9.82031% (1257/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 10.0312% (1284/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 10.0625% (1288/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 10.0469% (1286/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 9.64062% (1234/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 9.95312% (1274/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.1328% (1297/12800)
Accuracy = 10% (1280/12800)
Accuracy = 9.84375% (1260/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 10.1016% (1293/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 10.25% (1312/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 9.99219% (1279/12800)
Accuracy = 10.0703% (1289/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 9.89062% (1266/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 9.67969% (1239/12800)
Accuracy = 10.1328% (1297/12800)
Accuracy = 10.2109% (1307/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 9.71094% (1243/12800)
Accuracy = 10.1016% (1293/12800)
Accuracy = 9.9375% (1272/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 9.82812% (1258/12800)
Accuracy = 10.0938% (1292/12800)
Accuracy = 10.0312% (1284/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10% (1280/12800)
Accuracy = 10.1094% (1294/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 9.90625% (1268/12800)
Accuracy = 9.9375% (1272/12800)
Accuracy = 9.98438% (1278/12800)
Accuracy = 10.0781% (1290/12800)
Accuracy = 10.1406% (1298/12800)
Accuracy = 10.0625% (1288/12800)
Accuracy = 9.9375% (1272/12800)
Accuracy = 10.0781% (1290/12800)
Accuracy = 10.0703% (1289/12800)
Accuracy = 10.1484% (1299/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 10.0625% (1288/12800)
Accuracy = 9.77344% (1251/12800)
Accuracy = 9.99219% (1279/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 10.1406% (1298/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 9.99219% (1279/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 10.0547% (1287/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 10.0156% (1282/12800)
Load prediction file and append to a list
Get label for x_sub cost 615.7
Substitute data augmentation processing
Augmentation cost 31.7 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Oracle model FGSM attack's accuracy on adversarial samples #9800:
External call
Accuracy = 9.96939% (977/9800)
Accuracy = 10.1224% (992/9800)
Accuracy = 10.2347% (1003/9800)
Accuracy = 10.2449% (1004/9800)
Accuracy = 10.0204% (982/9800)
Accuracy = 10.2551% (1005/9800)
Accuracy = 10.1735% (997/9800)
Accuracy = 10.2449% (1004/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 10.0714% (987/9800)
Accuracy = 10.0714% (987/9800)
Accuracy = 10% (980/9800)
Accuracy = 10% (980/9800)
Accuracy = 10.102% (990/9800)
Accuracy = 10.6122% (1040/9800)
Accuracy = 10.398% (1019/9800)
Accuracy = 10.2449% (1004/9800)
Accuracy = 9.64286% (945/9800)
Accuracy = 9.90816% (971/9800)
Accuracy = 10.2245% (1002/9800)
Accuracy = 10.1837% (998/9800)
Accuracy = 10.2245% (1002/9800)
Accuracy = 10.2041% (1000/9800)
Accuracy = 9.94898% (975/9800)
Accuracy = 10.2959% (1009/9800)
Accuracy = 10.1224% (992/9800)
Accuracy = 10.1633% (996/9800)
Accuracy = 10.0306% (983/9800)
Accuracy = 9.73469% (954/9800)
Accuracy = 10.2857% (1008/9800)
Accuracy = 9.73469% (954/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 10.1633% (996/9800)
Accuracy = 10.0816% (988/9800)
Accuracy = 9.97959% (978/9800)
Accuracy = 10.6429% (1043/9800)
Accuracy = 10.0816% (988/9800)
Accuracy = 10.5918% (1038/9800)
Accuracy = 10.4286% (1022/9800)
Accuracy = 10.0204% (982/9800)
Accuracy = 9.86735% (967/9800)
Accuracy = 10.2551% (1005/9800)
Accuracy = 10.4898% (1028/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 10.3163% (1011/9800)
Accuracy = 10.1633% (996/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 10.3265% (1012/9800)
Accuracy = 10% (980/9800)
Accuracy = 10.2551% (1005/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 10.102% (990/9800)
Accuracy = 10.2347% (1003/9800)
Accuracy = 10.1224% (992/9800)
Accuracy = 10.0816% (988/9800)
Accuracy = 10.1429% (994/9800)
Accuracy = 10.449% (1024/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 10.1429% (994/9800)
Accuracy = 9.97959% (978/9800)
Accuracy = 10.0918% (989/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 10.051% (985/9800)
Accuracy = 9.87755% (968/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 10.3163% (1011/9800)
Accuracy = 10.3163% (1011/9800)
Accuracy = 9.94898% (975/9800)
Accuracy = 9.92857% (973/9800)
Accuracy = 10.0102% (981/9800)
Accuracy = 10.398% (1019/9800)
Accuracy = 10.0918% (989/9800)
Accuracy = 10.2041% (1000/9800)
Accuracy = 10.0204% (982/9800)
Accuracy = 10.2449% (1004/9800)
Accuracy = 10.2143% (1001/9800)
Accuracy = 10.3367% (1013/9800)
Accuracy = 10.2347% (1003/9800)
Accuracy = 10.2041% (1000/9800)
Accuracy = 10.3878% (1018/9800)
Accuracy = 10.1531% (995/9800)
Accuracy = 10.2347% (1003/9800)
Accuracy = 9.97959% (978/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 10.1327% (993/9800)
Accuracy = 10.0816% (988/9800)
Accuracy = 9.94898% (975/9800)
Accuracy = 10.1429% (994/9800)
Accuracy = 10.4898% (1028/9800)
Accuracy = 10.1429% (994/9800)
Accuracy = 10% (980/9800)
Accuracy = 10.3163% (1011/9800)
Accuracy = 10.2653% (1006/9800)
Accuracy = 10.2347% (1003/9800)
Accuracy = 10.2857% (1008/9800)
Accuracy = 10.2041% (1000/9800)
Accuracy = 10.2449% (1004/9800)
Accuracy = 10.0306% (983/9800)
Accuracy = 10.2755% (1007/9800)
Load prediction file and append to a list
correct_count:  0
Test accuray tensor:  0.0
Epoch #13:
Current x_sub's size is 12800
External call
Accuracy = 10.0625% (1288/12800)
Accuracy = 9.77344% (1251/12800)
Accuracy = 9.84375% (1260/12800)
Accuracy = 9.98438% (1278/12800)
Accuracy = 9.74219% (1247/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.59375% (1228/12800)
Accuracy = 10.2891% (1317/12800)
Accuracy = 10.0781% (1290/12800)
Accuracy = 9.78125% (1252/12800)
Accuracy = 9.98438% (1278/12800)
Accuracy = 9.90625% (1268/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 9.73438% (1246/12800)
Accuracy = 10.1094% (1294/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 9.82031% (1257/12800)
Accuracy = 10.0469% (1286/12800)
Accuracy = 9.625% (1232/12800)
Accuracy = 9.79688% (1254/12800)
Accuracy = 9.82031% (1257/12800)
Accuracy = 9.95312% (1274/12800)
Accuracy = 9.71875% (1244/12800)
Accuracy = 9.91406% (1269/12800)
Accuracy = 9.89062% (1266/12800)
Accuracy = 9.83594% (1259/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 9.9375% (1272/12800)
Accuracy = 9.70312% (1242/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 9.82031% (1257/12800)
Accuracy = 9.84375% (1260/12800)
Accuracy = 9.82812% (1258/12800)
Accuracy = 9.78906% (1253/12800)
Accuracy = 9.89062% (1266/12800)
Accuracy = 9.83594% (1259/12800)
Accuracy = 9.89062% (1266/12800)
Accuracy = 9.90625% (1268/12800)
Accuracy = 9.85938% (1262/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.79688% (1254/12800)
Accuracy = 9.99219% (1279/12800)
Accuracy = 10.0312% (1284/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 9.84375% (1260/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 10.1406% (1298/12800)
Accuracy = 9.78125% (1252/12800)
Accuracy = 9.77344% (1251/12800)
Accuracy = 9.78906% (1253/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 9.70312% (1242/12800)
Accuracy = 10% (1280/12800)
Accuracy = 9.91406% (1269/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 9.75% (1248/12800)
Accuracy = 9.73438% (1246/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 9.82031% (1257/12800)
Accuracy = 9.67969% (1239/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.8125% (1256/12800)
Accuracy = 10.0703% (1289/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 9.99219% (1279/12800)
Accuracy = 9.89062% (1266/12800)
Accuracy = 9.73438% (1246/12800)
Accuracy = 9.76562% (1250/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 9.64844% (1235/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.78906% (1253/12800)
Accuracy = 9.78906% (1253/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 9.64844% (1235/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 9.67969% (1239/12800)
Accuracy = 9.71875% (1244/12800)
Accuracy = 9.67969% (1239/12800)
Accuracy = 9.58594% (1227/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 9.82812% (1258/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 9.96094% (1275/12800)
Accuracy = 9.99219% (1279/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 9.95312% (1274/12800)
Accuracy = 9.98438% (1278/12800)
Accuracy = 9.74219% (1247/12800)
Accuracy = 9.91406% (1269/12800)
Load prediction file and append to a list
Get label for x_sub cost 614.5
Substitute data augmentation processing
Augmentation cost 34.1 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Epoch #14:
Current x_sub's size is 12800
External call
Accuracy = 9.76562% (1250/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 10.1484% (1299/12800)
Accuracy = 10.4219% (1334/12800)
Accuracy = 10.0312% (1284/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 10.0156% (1282/12800)
Accuracy = 10.4844% (1342/12800)
Accuracy = 10.0781% (1290/12800)
Accuracy = 9.80469% (1255/12800)
Accuracy = 10.125% (1296/12800)
Accuracy = 10.1719% (1302/12800)
Accuracy = 9.60156% (1229/12800)
Accuracy = 9.72656% (1245/12800)
Accuracy = 10.3359% (1323/12800)
Accuracy = 10.2969% (1318/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 10.5781% (1354/12800)
Accuracy = 10.1641% (1301/12800)
Accuracy = 9.99219% (1279/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 10.4922% (1343/12800)
Accuracy = 9.44531% (1209/12800)
Accuracy = 10.0156% (1282/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 10.4688% (1340/12800)
Accuracy = 9.64844% (1235/12800)
Accuracy = 10.2891% (1317/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 10.2188% (1308/12800)
Accuracy = 9.63281% (1233/12800)
Accuracy = 9.83594% (1259/12800)
Accuracy = 10.5547% (1351/12800)
Accuracy = 9.78906% (1253/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.5312% (1348/12800)
Accuracy = 10.5703% (1353/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 10.5625% (1352/12800)
Accuracy = 10.0703% (1289/12800)
Accuracy = 10.3828% (1329/12800)
Accuracy = 9.77344% (1251/12800)
Accuracy = 9.60938% (1230/12800)
Accuracy = 9.8125% (1256/12800)
Accuracy = 10.25% (1312/12800)
Accuracy = 10.1719% (1302/12800)
Accuracy = 9.89062% (1266/12800)
Accuracy = 9.59375% (1228/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 9.78906% (1253/12800)
Accuracy = 10.0391% (1285/12800)
Accuracy = 10.2969% (1318/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 10.0312% (1284/12800)
Accuracy = 10.3828% (1329/12800)
Accuracy = 9.78906% (1253/12800)
Accuracy = 10.5859% (1355/12800)
Accuracy = 9.91406% (1269/12800)
Accuracy = 9.89062% (1266/12800)
Accuracy = 10.1641% (1301/12800)
Accuracy = 9.35938% (1198/12800)
Accuracy = 9.74219% (1247/12800)
Accuracy = 9.6875% (1240/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 9.99219% (1279/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 9.79688% (1254/12800)
Accuracy = 10.4453% (1337/12800)
Accuracy = 9.64062% (1234/12800)
Accuracy = 10.0469% (1286/12800)
Accuracy = 9.98438% (1278/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 10.2656% (1314/12800)
Accuracy = 10.2109% (1307/12800)
Accuracy = 10.0703% (1289/12800)
Accuracy = 10.5078% (1345/12800)
Accuracy = 9.83594% (1259/12800)
Accuracy = 9.99219% (1279/12800)
Accuracy = 10.0469% (1286/12800)
Accuracy = 9.67188% (1238/12800)
Accuracy = 9.90625% (1268/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 10.2422% (1311/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 9.71094% (1243/12800)
Accuracy = 9.60156% (1229/12800)
Accuracy = 10.1641% (1301/12800)
Accuracy = 10.375% (1328/12800)
Accuracy = 9.51562% (1218/12800)
Accuracy = 10.1484% (1299/12800)
Accuracy = 9.76562% (1250/12800)
Accuracy = 10.2812% (1316/12800)
Accuracy = 10.5859% (1355/12800)
Accuracy = 9.83594% (1259/12800)
Accuracy = 10.4688% (1340/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 10.2344% (1310/12800)
Load prediction file and append to a list
Get label for x_sub cost 614.8
Substitute data augmentation processing
Augmentation cost 28.7 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Oracle model FGSM attack's accuracy on adversarial samples #9800:
External call
Accuracy = 10% (980/9800)
Accuracy = 10.1224% (992/9800)
Accuracy = 9.63265% (944/9800)
Accuracy = 9.79592% (960/9800)
Accuracy = 10.1429% (994/9800)
Accuracy = 9.81633% (962/9800)
Accuracy = 9.97959% (978/9800)
Accuracy = 9.73469% (954/9800)
Accuracy = 9.78571% (959/9800)
Accuracy = 9.87755% (968/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 9.5% (931/9800)
Accuracy = 9.92857% (973/9800)
Accuracy = 9.81633% (962/9800)
Accuracy = 9.55102% (936/9800)
Accuracy = 9.66327% (947/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 10.1531% (995/9800)
Accuracy = 9.80612% (961/9800)
Accuracy = 10.0306% (983/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 9.90816% (971/9800)
Accuracy = 10.0612% (986/9800)
Accuracy = 9.69388% (950/9800)
Accuracy = 10.102% (990/9800)
Accuracy = 9.91837% (972/9800)
Accuracy = 9.89796% (970/9800)
Accuracy = 9.68367% (949/9800)
Accuracy = 10.1327% (993/9800)
Accuracy = 9.94898% (975/9800)
Accuracy = 10.0612% (986/9800)
Accuracy = 9.93878% (974/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 10.0306% (983/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 9.85714% (966/9800)
Accuracy = 9.70408% (951/9800)
Accuracy = 9.88776% (969/9800)
Accuracy = 10.1429% (994/9800)
Accuracy = 9.65306% (946/9800)
Accuracy = 10% (980/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 9.86735% (967/9800)
Accuracy = 9.93878% (974/9800)
Accuracy = 10.0714% (987/9800)
Accuracy = 9.82653% (963/9800)
Accuracy = 9.86735% (967/9800)
Accuracy = 10.0102% (981/9800)
Accuracy = 9.86735% (967/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 10.0408% (984/9800)
Accuracy = 9.70408% (951/9800)
Accuracy = 10% (980/9800)
Accuracy = 9.89796% (970/9800)
Accuracy = 9.7551% (956/9800)
Accuracy = 9.89796% (970/9800)
Accuracy = 10.1224% (992/9800)
Accuracy = 9.77551% (958/9800)
Accuracy = 9.77551% (958/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 10.0102% (981/9800)
Accuracy = 9.95918% (976/9800)
Accuracy = 9.80612% (961/9800)
Accuracy = 9.86735% (967/9800)
Accuracy = 10.2449% (1004/9800)
Accuracy = 10.1735% (997/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 10.1633% (996/9800)
Accuracy = 9.82653% (963/9800)
Accuracy = 9.73469% (954/9800)
Accuracy = 9.7449% (955/9800)
Accuracy = 9.79592% (960/9800)
Accuracy = 9.93878% (974/9800)
Accuracy = 9.72449% (953/9800)
Accuracy = 9.63265% (944/9800)
Accuracy = 10.2551% (1005/9800)
Accuracy = 10.398% (1019/9800)
Accuracy = 9.64286% (945/9800)
Accuracy = 9.86735% (967/9800)
Accuracy = 9.79592% (960/9800)
Accuracy = 9.92857% (973/9800)
Accuracy = 9.91837% (972/9800)
Accuracy = 9.91837% (972/9800)
Accuracy = 9.79592% (960/9800)
Accuracy = 10.0714% (987/9800)
Accuracy = 9.93878% (974/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 9.82653% (963/9800)
Accuracy = 10.0816% (988/9800)
Accuracy = 10.0306% (983/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 10.0102% (981/9800)
Accuracy = 9.65306% (946/9800)
Accuracy = 9.80612% (961/9800)
Accuracy = 9.78571% (959/9800)
Accuracy = 9.67347% (948/9800)
Accuracy = 9.97959% (978/9800)
Accuracy = 10.0918% (989/9800)
Accuracy = 10% (980/9800)
Load prediction file and append to a list
correct_count:  0
Test accuray tensor:  0.0
Epoch #15:
Current x_sub's size is 12800
External call
Accuracy = 10.1797% (1303/12800)
Accuracy = 9.80469% (1255/12800)
Accuracy = 9.80469% (1255/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 9.9375% (1272/12800)
Accuracy = 9.74219% (1247/12800)
Accuracy = 9.78906% (1253/12800)
Accuracy = 9.84375% (1260/12800)
Accuracy = 9.82031% (1257/12800)
Accuracy = 9.60156% (1229/12800)
Accuracy = 9.83594% (1259/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 9.82031% (1257/12800)
Accuracy = 9.78906% (1253/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.69531% (1241/12800)
Accuracy = 9.9375% (1272/12800)
Accuracy = 9.8125% (1256/12800)
Accuracy = 9.95312% (1274/12800)
Accuracy = 9.65625% (1236/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 9.85938% (1262/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 9.84375% (1260/12800)
Accuracy = 10.0547% (1287/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 9.79688% (1254/12800)
Accuracy = 9.75781% (1249/12800)
Accuracy = 9.8125% (1256/12800)
Accuracy = 9.79688% (1254/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 10.1406% (1298/12800)
Accuracy = 9.73438% (1246/12800)
Accuracy = 9.91406% (1269/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 9.75781% (1249/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 9.83594% (1259/12800)
Accuracy = 10.0391% (1285/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 9.85938% (1262/12800)
Accuracy = 9.9375% (1272/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.85938% (1262/12800)
Accuracy = 9.84375% (1260/12800)
Accuracy = 10.25% (1312/12800)
Accuracy = 9.77344% (1251/12800)
Accuracy = 9.79688% (1254/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.75% (1248/12800)
Accuracy = 9.82031% (1257/12800)
Accuracy = 9.80469% (1255/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 9.72656% (1245/12800)
Accuracy = 9.77344% (1251/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 9.77344% (1251/12800)
Accuracy = 9.78906% (1253/12800)
Accuracy = 9.95312% (1274/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 9.79688% (1254/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 9.44531% (1209/12800)
Accuracy = 9.84375% (1260/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 9.78906% (1253/12800)
Accuracy = 10.0469% (1286/12800)
Accuracy = 9.71875% (1244/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 9.75781% (1249/12800)
Accuracy = 9.80469% (1255/12800)
Accuracy = 9.79688% (1254/12800)
Accuracy = 9.85938% (1262/12800)
Accuracy = 9.78906% (1253/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 9.82812% (1258/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 9.75781% (1249/12800)
Accuracy = 9.90625% (1268/12800)
Accuracy = 9.79688% (1254/12800)
Accuracy = 9.98438% (1278/12800)
Accuracy = 9.75781% (1249/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 9.83594% (1259/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 9.89062% (1266/12800)
Accuracy = 9.85938% (1262/12800)
Accuracy = 9.84375% (1260/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 9.96094% (1275/12800)
Load prediction file and append to a list
Get label for x_sub cost 615.4
Substitute data augmentation processing
Augmentation cost 28.8 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Epoch #16:
Current x_sub's size is 12800
External call
Accuracy = 9.8125% (1256/12800)
Accuracy = 10.0703% (1289/12800)
Accuracy = 10.3125% (1320/12800)
Accuracy = 10.5078% (1345/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 10.6484% (1363/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.1719% (1302/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 10.1406% (1298/12800)
Accuracy = 9.90625% (1268/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 9.57031% (1225/12800)
Accuracy = 10.4766% (1341/12800)
Accuracy = 10.5078% (1345/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.0547% (1287/12800)
Accuracy = 10.2969% (1318/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.4531% (1338/12800)
Accuracy = 9.71875% (1244/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.0781% (1290/12800)
Accuracy = 10.5156% (1346/12800)
Accuracy = 9.8125% (1256/12800)
Accuracy = 10.375% (1328/12800)
Accuracy = 9.64844% (1235/12800)
Accuracy = 10.4375% (1336/12800)
Accuracy = 10.0781% (1290/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 10.1406% (1298/12800)
Accuracy = 10.1719% (1302/12800)
Accuracy = 10.5% (1344/12800)
Accuracy = 10.2578% (1313/12800)
Accuracy = 10.7812% (1380/12800)
Accuracy = 10.5625% (1352/12800)
Accuracy = 10.4844% (1342/12800)
Accuracy = 10.4219% (1334/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 9.38281% (1201/12800)
Accuracy = 9.84375% (1260/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 10.0156% (1282/12800)
Accuracy = 10.25% (1312/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 10.2734% (1315/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 10.4141% (1333/12800)
Accuracy = 10.6406% (1362/12800)
Accuracy = 10.4531% (1338/12800)
Accuracy = 9.96094% (1275/12800)
Accuracy = 9.98438% (1278/12800)
Accuracy = 10.3281% (1322/12800)
Accuracy = 10.3203% (1321/12800)
Accuracy = 9.98438% (1278/12800)
Accuracy = 10.3438% (1324/12800)
Accuracy = 9.85938% (1262/12800)
Accuracy = 9.89062% (1266/12800)
Accuracy = 9.64844% (1235/12800)
Accuracy = 9.79688% (1254/12800)
Accuracy = 10% (1280/12800)
Accuracy = 10.2344% (1310/12800)
Accuracy = 10.3438% (1324/12800)
Accuracy = 10.3203% (1321/12800)
Accuracy = 10.25% (1312/12800)
Accuracy = 10.3047% (1319/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 10.2656% (1314/12800)
Accuracy = 10.2422% (1311/12800)
Accuracy = 10.3203% (1321/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 9.83594% (1259/12800)
Accuracy = 10.7031% (1370/12800)
Accuracy = 10.1016% (1293/12800)
Accuracy = 10.2344% (1310/12800)
Accuracy = 10.4844% (1342/12800)
Accuracy = 10.2656% (1314/12800)
Accuracy = 10.3594% (1326/12800)
Accuracy = 9.75% (1248/12800)
Accuracy = 10.4609% (1339/12800)
Accuracy = 9.79688% (1254/12800)
Accuracy = 10.2344% (1310/12800)
Accuracy = 10.3516% (1325/12800)
Accuracy = 10.2266% (1309/12800)
Accuracy = 9.70312% (1242/12800)
Accuracy = 10.2812% (1316/12800)
Accuracy = 10.3516% (1325/12800)
Accuracy = 10.0156% (1282/12800)
Accuracy = 10.2578% (1313/12800)
Accuracy = 10.0938% (1292/12800)
Accuracy = 10.4375% (1336/12800)
Accuracy = 10.5859% (1355/12800)
Accuracy = 10.2266% (1309/12800)
Accuracy = 10.1406% (1298/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.375% (1328/12800)
Accuracy = 10.4531% (1338/12800)
Load prediction file and append to a list
Get label for x_sub cost 614.8
Substitute data augmentation processing
Augmentation cost 28.7 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Oracle model FGSM attack's accuracy on adversarial samples #9800:
External call
Accuracy = 9.87755% (968/9800)
Accuracy = 10.0204% (982/9800)
Accuracy = 9.80612% (961/9800)
Accuracy = 9.94898% (975/9800)
Accuracy = 10.1633% (996/9800)
Accuracy = 10.3673% (1016/9800)
Accuracy = 9.90816% (971/9800)
Accuracy = 9.90816% (971/9800)
Accuracy = 10.0102% (981/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 9.89796% (970/9800)
Accuracy = 9.70408% (951/9800)
Accuracy = 9.91837% (972/9800)
Accuracy = 9.86735% (967/9800)
Accuracy = 9.69388% (950/9800)
Accuracy = 9.65306% (946/9800)
Accuracy = 10% (980/9800)
Accuracy = 10.0408% (984/9800)
Accuracy = 10.0816% (988/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 10.1327% (993/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 10.1531% (995/9800)
Accuracy = 10.2143% (1001/9800)
Accuracy = 9.7551% (956/9800)
Accuracy = 10.2041% (1000/9800)
Accuracy = 10.0408% (984/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 10.051% (985/9800)
Accuracy = 10.1633% (996/9800)
Accuracy = 9.55102% (936/9800)
Accuracy = 9.85714% (966/9800)
Accuracy = 10.3878% (1018/9800)
Accuracy = 9.82653% (963/9800)
Accuracy = 10.3163% (1011/9800)
Accuracy = 10.2143% (1001/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 10.2755% (1007/9800)
Accuracy = 9.88776% (969/9800)
Accuracy = 9.94898% (975/9800)
Accuracy = 10.051% (985/9800)
Accuracy = 9.94898% (975/9800)
Accuracy = 9.97959% (978/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 9.93878% (974/9800)
Accuracy = 9.71429% (952/9800)
Accuracy = 10.3061% (1010/9800)
Accuracy = 9.87755% (968/9800)
Accuracy = 10.051% (985/9800)
Accuracy = 9.93878% (974/9800)
Accuracy = 9.57143% (938/9800)
Accuracy = 10.3571% (1015/9800)
Accuracy = 9.71429% (952/9800)
Accuracy = 10.1224% (992/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 10.102% (990/9800)
Accuracy = 9.95918% (976/9800)
Accuracy = 9.65306% (946/9800)
Accuracy = 10.1327% (993/9800)
Accuracy = 9.72449% (953/9800)
Accuracy = 9.88776% (969/9800)
Accuracy = 10.0816% (988/9800)
Accuracy = 9.73469% (954/9800)
Accuracy = 9.76531% (957/9800)
Accuracy = 10.0816% (988/9800)
Accuracy = 10.0816% (988/9800)
Accuracy = 9.78571% (959/9800)
Accuracy = 10.0408% (984/9800)
Accuracy = 10.2245% (1002/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 9.71429% (952/9800)
Accuracy = 10.2653% (1006/9800)
Accuracy = 10.2041% (1000/9800)
Accuracy = 10.1429% (994/9800)
Accuracy = 10.1633% (996/9800)
Accuracy = 9.89796% (970/9800)
Accuracy = 9.91837% (972/9800)
Accuracy = 9.80612% (961/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 10.1224% (992/9800)
Accuracy = 9.78571% (959/9800)
Accuracy = 9.89796% (970/9800)
Accuracy = 9.82653% (963/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 10.0204% (982/9800)
Accuracy = 9.83673% (964/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 9.7449% (955/9800)
Accuracy = 10.1224% (992/9800)
Accuracy = 9.91837% (972/9800)
Accuracy = 10.2041% (1000/9800)
Accuracy = 9.69388% (950/9800)
Accuracy = 10.051% (985/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 10.2449% (1004/9800)
Accuracy = 10% (980/9800)
Accuracy = 10.0612% (986/9800)
Accuracy = 10.0204% (982/9800)
Load prediction file and append to a list
correct_count:  0
Test accuray tensor:  0.0
Epoch #17:
Current x_sub's size is 12800
External call
Accuracy = 9.96875% (1276/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 9.96094% (1275/12800)
Accuracy = 9.96094% (1275/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 9.98438% (1278/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 10.0312% (1284/12800)
Accuracy = 10.1094% (1294/12800)
Accuracy = 10.1094% (1294/12800)
Accuracy = 9.78125% (1252/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 10.2422% (1311/12800)
Accuracy = 10.0156% (1282/12800)
Accuracy = 9.9375% (1272/12800)
Accuracy = 10.0312% (1284/12800)
Accuracy = 9.95312% (1274/12800)
Accuracy = 10.2031% (1306/12800)
Accuracy = 10.0703% (1289/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 9.84375% (1260/12800)
Accuracy = 10.2969% (1318/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.91406% (1269/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 10.0469% (1286/12800)
Accuracy = 9.99219% (1279/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 10.0312% (1284/12800)
Accuracy = 10.1484% (1299/12800)
Accuracy = 9.84375% (1260/12800)
Accuracy = 9.9375% (1272/12800)
Accuracy = 9.96094% (1275/12800)
Accuracy = 10.2656% (1314/12800)
Accuracy = 9.99219% (1279/12800)
Accuracy = 10.1328% (1297/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 9.89062% (1266/12800)
Accuracy = 10.1016% (1293/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 10.2891% (1317/12800)
Accuracy = 10.0703% (1289/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 9.90625% (1268/12800)
Accuracy = 9.9375% (1272/12800)
Accuracy = 9.80469% (1255/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 10% (1280/12800)
Accuracy = 9.9375% (1272/12800)
Accuracy = 9.72656% (1245/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 9.99219% (1279/12800)
Accuracy = 10.1719% (1302/12800)
Accuracy = 10.0547% (1287/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 10.1094% (1294/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 9.91406% (1269/12800)
Accuracy = 9.95312% (1274/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 10.1797% (1303/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 9.79688% (1254/12800)
Accuracy = 10.1406% (1298/12800)
Accuracy = 10.1172% (1295/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 10.0469% (1286/12800)
Accuracy = 9.96094% (1275/12800)
Accuracy = 9.91406% (1269/12800)
Accuracy = 10.5703% (1353/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 9.90625% (1268/12800)
Accuracy = 9.91406% (1269/12800)
Accuracy = 10.25% (1312/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 10% (1280/12800)
Accuracy = 10.1406% (1298/12800)
Accuracy = 10% (1280/12800)
Accuracy = 10% (1280/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 10.0547% (1287/12800)
Accuracy = 9.99219% (1279/12800)
Accuracy = 10.0156% (1282/12800)
Load prediction file and append to a list
Get label for x_sub cost 616.0
Substitute data augmentation processing
Augmentation cost 29.2 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Epoch #18:
Current x_sub's size is 12800
External call
Accuracy = 9.42969% (1207/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 10.3438% (1324/12800)
Accuracy = 9.78906% (1253/12800)
Accuracy = 9.79688% (1254/12800)
Accuracy = 10.375% (1328/12800)
Accuracy = 9.89062% (1266/12800)
Accuracy = 10.0703% (1289/12800)
Accuracy = 9.85156% (1261/12800)
Accuracy = 10.2812% (1316/12800)
Accuracy = 9.83594% (1259/12800)
Accuracy = 9.8125% (1256/12800)
Accuracy = 10.3125% (1320/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 10.3906% (1330/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 10.2656% (1314/12800)
Accuracy = 9.95312% (1274/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 10.2266% (1309/12800)
Accuracy = 9.67188% (1238/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 9.63281% (1233/12800)
Accuracy = 9.82812% (1258/12800)
Accuracy = 9.95312% (1274/12800)
Accuracy = 10.1641% (1301/12800)
Accuracy = 10.2422% (1311/12800)
Accuracy = 10.1484% (1299/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 10.2266% (1309/12800)
Accuracy = 10.0625% (1288/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 9.70312% (1242/12800)
Accuracy = 10.2812% (1316/12800)
Accuracy = 9.72656% (1245/12800)
Accuracy = 10.5156% (1346/12800)
Accuracy = 9.86719% (1263/12800)
Accuracy = 10.1953% (1305/12800)
Accuracy = 9.42969% (1207/12800)
Accuracy = 9.85938% (1262/12800)
Accuracy = 10.0625% (1288/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 10.0312% (1284/12800)
Accuracy = 9.75781% (1249/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 9.84375% (1260/12800)
Accuracy = 10.0234% (1283/12800)
Accuracy = 10.2422% (1311/12800)
Accuracy = 9.67188% (1238/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 9.79688% (1254/12800)
Accuracy = 10.2422% (1311/12800)
Accuracy = 10.1328% (1297/12800)
Accuracy = 9.625% (1232/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 10.2578% (1313/12800)
Accuracy = 9.71875% (1244/12800)
Accuracy = 9.72656% (1245/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 10.2656% (1314/12800)
Accuracy = 9.94531% (1273/12800)
Accuracy = 10.4688% (1340/12800)
Accuracy = 10.0859% (1291/12800)
Accuracy = 10.2422% (1311/12800)
Accuracy = 10.0391% (1285/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 10.3828% (1329/12800)
Accuracy = 9.89062% (1266/12800)
Accuracy = 9.76562% (1250/12800)
Accuracy = 9.96094% (1275/12800)
Accuracy = 9.92188% (1270/12800)
Accuracy = 9.57812% (1226/12800)
Accuracy = 10.4453% (1337/12800)
Accuracy = 10.3281% (1322/12800)
Accuracy = 9.67188% (1238/12800)
Accuracy = 9.85938% (1262/12800)
Accuracy = 10.0703% (1289/12800)
Accuracy = 9.97656% (1277/12800)
Accuracy = 9.98438% (1278/12800)
Accuracy = 9.92969% (1271/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 9.875% (1264/12800)
Accuracy = 9.88281% (1265/12800)
Accuracy = 9.82812% (1258/12800)
Accuracy = 10.3594% (1326/12800)
Accuracy = 9.9375% (1272/12800)
Accuracy = 10.2109% (1307/12800)
Accuracy = 9.82812% (1258/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 10.1562% (1300/12800)
Accuracy = 10.1641% (1301/12800)
Accuracy = 10.1406% (1298/12800)
Accuracy = 9.96094% (1275/12800)
Accuracy = 9.89844% (1267/12800)
Accuracy = 9.67188% (1238/12800)
Load prediction file and append to a list
Get label for x_sub cost 615.5
Substitute data augmentation processing
Augmentation cost 28.5 seconds
getting grads on epsilon=0.0625
generating adversarial examples
Oracle model FGSM attack's accuracy on adversarial samples #9800:
External call
Accuracy = 9.63265% (944/9800)
Accuracy = 10.1224% (992/9800)
Accuracy = 9.95918% (976/9800)
Accuracy = 10.1327% (993/9800)
Accuracy = 10.1837% (998/9800)
Accuracy = 9.72449% (953/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 10.0918% (989/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 9.88776% (969/9800)
Accuracy = 9.85714% (966/9800)
Accuracy = 10.6531% (1044/9800)
Accuracy = 9.88776% (969/9800)
Accuracy = 9.76531% (957/9800)
Accuracy = 10.4796% (1027/9800)
Accuracy = 10.0714% (987/9800)
Accuracy = 9.78571% (959/9800)
Accuracy = 10.2959% (1009/9800)
Accuracy = 9.97959% (978/9800)
Accuracy = 9.77551% (958/9800)
Accuracy = 9.81633% (962/9800)
Accuracy = 10.0714% (987/9800)
Accuracy = 9.77551% (958/9800)
Accuracy = 9.82653% (963/9800)
Accuracy = 10.051% (985/9800)
Accuracy = 9.70408% (951/9800)
Accuracy = 9.7551% (956/9800)
Accuracy = 10.0102% (981/9800)
Accuracy = 10.2245% (1002/9800)
Accuracy = 9.94898% (975/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 9.88776% (969/9800)
Accuracy = 10.0102% (981/9800)
Accuracy = 9.7449% (955/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 9.89796% (970/9800)
Accuracy = 10.4082% (1020/9800)
Accuracy = 9.68367% (949/9800)
Accuracy = 10.6939% (1048/9800)
Accuracy = 9.77551% (958/9800)
Accuracy = 9.70408% (951/9800)
Accuracy = 9.85714% (966/9800)
Accuracy = 9.92857% (973/9800)
Accuracy = 9.87755% (968/9800)
Accuracy = 9.94898% (975/9800)
Accuracy = 10% (980/9800)
Accuracy = 9.70408% (951/9800)
Accuracy = 9.87755% (968/9800)
Accuracy = 9.86735% (967/9800)
Accuracy = 9.78571% (959/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 9.95918% (976/9800)
Accuracy = 9.82653% (963/9800)
Accuracy = 9.7449% (955/9800)
Accuracy = 9.83673% (964/9800)
Accuracy = 10.0102% (981/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 10.1531% (995/9800)
Accuracy = 10.0102% (981/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 9.85714% (966/9800)
Accuracy = 9.89796% (970/9800)
Accuracy = 9.64286% (945/9800)
Accuracy = 9.80612% (961/9800)
Accuracy = 9.77551% (958/9800)
Accuracy = 9.78571% (959/9800)
Accuracy = 10.4694% (1026/9800)
Accuracy = 9.92857% (973/9800)
Accuracy = 10.0714% (987/9800)
Accuracy = 10.0816% (988/9800)
Accuracy = 9.91837% (972/9800)
Accuracy = 10.102% (990/9800)
Accuracy = 10% (980/9800)
Accuracy = 9.83673% (964/9800)
Accuracy = 9.85714% (966/9800)
Accuracy = 9.87755% (968/9800)
Accuracy = 9.87755% (968/9800)
Accuracy = 10.5204% (1031/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 9.80612% (961/9800)
Accuracy = 9.87755% (968/9800)
Accuracy = 9.92857% (973/9800)
Accuracy = 9.79592% (960/9800)
Accuracy = 9.91837% (972/9800)
Accuracy = 9.93878% (974/9800)
Accuracy = 9.72449% (953/9800)
Accuracy = 9.88776% (969/9800)
Accuracy = 9.92857% (973/9800)
Accuracy = 10.0102% (981/9800)
Accuracy = 10.5714% (1036/9800)
Accuracy = 9.73469% (954/9800)
Accuracy = 9.82653% (963/9800)
Accuracy = 9.83673% (964/9800)
Accuracy = 10.051% (985/9800)
Accuracy = 10.102% (990/9800)
Accuracy = 9.91837% (972/9800)
Accuracy = 9.77551% (958/9800)
Accuracy = 9.81633% (962/9800)
Accuracy = 9.83673% (964/9800)
Accuracy = 9.92857% (973/9800)
Load prediction file and append to a list
correct_count:  0
Test accuray tensor:  0.0
Epoch #19:
Current x_sub's size is 12800
External call
Accuracy = 10.2266% (1309/12800)
Accuracy = 10.6016% (1357/12800)
Accuracy = 10.5156% (1346/12800)
Accuracy = 10.5547% (1351/12800)
Accuracy = 10.4688% (1340/12800)
Accuracy = 10.4688% (1340/12800)
Accuracy = 10.4609% (1339/12800)
Accuracy = 10.4766% (1341/12800)
Accuracy = 10.3828% (1329/12800)
Accuracy = 10.3125% (1320/12800)
Accuracy = 10.4297% (1335/12800)
Accuracy = 10.3125% (1320/12800)
Accuracy = 10.2734% (1315/12800)
Accuracy = 10.4531% (1338/12800)
Accuracy = 10.5938% (1356/12800)
Accuracy = 10.6797% (1367/12800)
Accuracy = 10.5391% (1349/12800)
Accuracy = 10.2969% (1318/12800)
Accuracy = 10.5078% (1345/12800)
Accuracy = 10.5% (1344/12800)
Accuracy = 10.4297% (1335/12800)
Accuracy = 10.5391% (1349/12800)
Accuracy = 10.5156% (1346/12800)
Accuracy = 10.3516% (1325/12800)
Accuracy = 10.7344% (1374/12800)
Accuracy = 10.4531% (1338/12800)
Accuracy = 10.2734% (1315/12800)
Accuracy = 10.4922% (1343/12800)
Accuracy = 10.5078% (1345/12800)
Accuracy = 10.4688% (1340/12800)
Accuracy = 10.4453% (1337/12800)
Accuracy = 10.4141% (1333/12800)
Accuracy = 10.4609% (1339/12800)
Accuracy = 10.5469% (1350/12800)
Accuracy = 10.4844% (1342/12800)
Accuracy = 9.96875% (1276/12800)
Accuracy = 10.3984% (1331/12800)
Accuracy = 10.3906% (1330/12800)
Accuracy = 10.6406% (1362/12800)
Accuracy = 10.6562% (1364/12800)
Accuracy = 10.4844% (1342/12800)
Accuracy = 10.3672% (1327/12800)
Accuracy = 10.4688% (1340/12800)
Accuracy = 10.6719% (1366/12800)
Accuracy = 10.7031% (1370/12800)
Accuracy = 10.5078% (1345/12800)
Accuracy = 10.5312% (1348/12800)
Accuracy = 10.4375% (1336/12800)
Accuracy = 10.5859% (1355/12800)
Accuracy = 10.4453% (1337/12800)
Accuracy = 10.3516% (1325/12800)
Accuracy = 10.4297% (1335/12800)
Accuracy = 10.4531% (1338/12800)
Accuracy = 10.5078% (1345/12800)
Accuracy = 10.4766% (1341/12800)
Accuracy = 10.4609% (1339/12800)
Accuracy = 10.5391% (1349/12800)
Accuracy = 10.0078% (1281/12800)
Accuracy = 10.5% (1344/12800)
Accuracy = 10.4766% (1341/12800)
Accuracy = 10.4297% (1335/12800)
Accuracy = 10.5% (1344/12800)
Accuracy = 10.625% (1360/12800)
Accuracy = 10.2812% (1316/12800)
Accuracy = 10.5547% (1351/12800)
Accuracy = 10.4688% (1340/12800)
Accuracy = 10.5391% (1349/12800)
Accuracy = 10.5547% (1351/12800)
Accuracy = 10.2266% (1309/12800)
Accuracy = 10.2422% (1311/12800)
Accuracy = 10.4688% (1340/12800)
Accuracy = 10.5391% (1349/12800)
Accuracy = 10.5859% (1355/12800)
Accuracy = 10.3281% (1322/12800)
Accuracy = 10.3672% (1327/12800)
Accuracy = 10.4375% (1336/12800)
Accuracy = 10.25% (1312/12800)
Accuracy = 10.7422% (1375/12800)
Accuracy = 10.4922% (1343/12800)
Accuracy = 10.5% (1344/12800)
Accuracy = 10.75% (1376/12800)
Accuracy = 10.3516% (1325/12800)
Accuracy = 10.5% (1344/12800)
Accuracy = 10.3672% (1327/12800)
Accuracy = 10.625% (1360/12800)
Accuracy = 10.5312% (1348/12800)
Accuracy = 10.4609% (1339/12800)
Accuracy = 10.1719% (1302/12800)
Accuracy = 10.2891% (1317/12800)
Accuracy = 10.5703% (1353/12800)
Accuracy = 10.5547% (1351/12800)
Accuracy = 10.4766% (1341/12800)
Accuracy = 10.5469% (1350/12800)
Accuracy = 10.4922% (1343/12800)
Accuracy = 10.4844% (1342/12800)
Accuracy = 10.5859% (1355/12800)
Accuracy = 10.5391% (1349/12800)
Accuracy = 10.4062% (1332/12800)
Accuracy = 10.4141% (1333/12800)
Accuracy = 10.5391% (1349/12800)
Load prediction file and append to a list
Get label for x_sub cost 803.1
getting grads on epsilon=0.0625
generating adversarial examples
Saving test adv data
Oracle model FGSM attack's accuracy on adversarial samples #9800:
External call
Accuracy = 10.0816% (988/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 9.97959% (978/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 10% (980/9800)
Accuracy = 9.93878% (974/9800)
Accuracy = 9.72449% (953/9800)
Accuracy = 9.80612% (961/9800)
Accuracy = 10.0408% (984/9800)
Accuracy = 9.65306% (946/9800)
Accuracy = 9.89796% (970/9800)
Accuracy = 9.77551% (958/9800)
Accuracy = 9.90816% (971/9800)
Accuracy = 9.7449% (955/9800)
Accuracy = 9.79592% (960/9800)
Accuracy = 10.1224% (992/9800)
Accuracy = 9.57143% (938/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 10.0612% (986/9800)
Accuracy = 10.0204% (982/9800)
Accuracy = 10% (980/9800)
Accuracy = 9.92857% (973/9800)
Accuracy = 9.68367% (949/9800)
Accuracy = 10.3265% (1012/9800)
Accuracy = 9.97959% (978/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 9.90816% (971/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 9.73469% (954/9800)
Accuracy = 10.1327% (993/9800)
Accuracy = 9.94898% (975/9800)
Accuracy = 9.90816% (971/9800)
Accuracy = 9.94898% (975/9800)
Accuracy = 9.80612% (961/9800)
Accuracy = 10.051% (985/9800)
Accuracy = 10.3061% (1010/9800)
Accuracy = 9.69388% (950/9800)
Accuracy = 10.051% (985/9800)
Accuracy = 9.79592% (960/9800)
Accuracy = 10% (980/9800)
Accuracy = 10.0816% (988/9800)
Accuracy = 9.86735% (967/9800)
Accuracy = 9.91837% (972/9800)
Accuracy = 10.1122% (991/9800)
Accuracy = 10.2959% (1009/9800)
Accuracy = 10.1633% (996/9800)
Accuracy = 9.9898% (979/9800)
Accuracy = 9.85714% (966/9800)
Accuracy = 10.2245% (1002/9800)
Accuracy = 9.73469% (954/9800)
Accuracy = 10.0816% (988/9800)
Accuracy = 10.1224% (992/9800)
Accuracy = 9.94898% (975/9800)
Accuracy = 9.91837% (972/9800)
Accuracy = 10.1327% (993/9800)
Accuracy = 10.0612% (986/9800)
Accuracy = 9.71429% (952/9800)
Accuracy = 10.1837% (998/9800)
Accuracy = 10.1837% (998/9800)
Accuracy = 9.94898% (975/9800)
Accuracy = 9.61224% (942/9800)
Accuracy = 9.67347% (948/9800)
Accuracy = 9.91837% (972/9800)
Accuracy = 9.88776% (969/9800)
Accuracy = 9.80612% (961/9800)
Accuracy = 10.1939% (999/9800)
Accuracy = 9.80612% (961/9800)
Accuracy = 10.1837% (998/9800)
Accuracy = 10.1327% (993/9800)
Accuracy = 9.67347% (948/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 9.95918% (976/9800)
Accuracy = 9.96939% (977/9800)
Accuracy = 10.051% (985/9800)
Accuracy = 9.89796% (970/9800)
Accuracy = 10.0714% (987/9800)
Accuracy = 9.84694% (965/9800)
Accuracy = 9.82653% (963/9800)
Accuracy = 9.83673% (964/9800)
Accuracy = 10% (980/9800)
Accuracy = 10.1224% (992/9800)
Accuracy = 10.0102% (981/9800)
Accuracy = 10.1531% (995/9800)
Accuracy = 9.91837% (972/9800)
Accuracy = 10.2347% (1003/9800)
Accuracy = 9.85714% (966/9800)
Accuracy = 9.93878% (974/9800)
Accuracy = 9.65306% (946/9800)
Accuracy = 10.2959% (1009/9800)
Accuracy = 9.63265% (944/9800)
Accuracy = 10.0306% (983/9800)
Accuracy = 9.82653% (963/9800)
Accuracy = 10.102% (990/9800)
Accuracy = 10.2041% (1000/9800)
Accuracy = 10% (980/9800)
Accuracy = 10.2857% (1008/9800)
Accuracy = 10.1429% (994/9800)
Accuracy = 10.0408% (984/9800)
Accuracy = 9.78571% (959/9800)
Accuracy = 10.3265% (1012/9800)
Load prediction file and append to a list
correct_count:  0
Test accuray tensor:  0.0


Final results:
Substitute model evaluation on clean data: #9800:
Test_accuracy: 0.18133
